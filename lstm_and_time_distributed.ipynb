{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_and_time_distributed.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianmarino/12-RNN/blob/master/lstm_and_time_distributed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DxliPix7Iyr4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando TimeDistributed en una LSTM"
      ]
    },
    {
      "metadata": {
        "id": "EZhlHZXTvhW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One to One"
      ]
    },
    {
      "metadata": {
        "id": "m-jtitj0FWLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2M4jFblFWLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93f582e6-2b91-4cf2-9247-e029101d475c"
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QvkTp12bhqli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funciones axiliares\n",
        "\n",
        "La idea es no mostrar c√≥digo repetido en los ejemplos. Recomiendo analizar estasss funciones  cuando se llegue al momento de utilizarlas.\n"
      ]
    },
    {
      "metadata": {
        "id": "-59ZTMAFGmF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show(model): \n",
        "  model.summary()\n",
        "  dot_mode = model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg')\n",
        "  display(SVG(dot_mode))\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    input_shape, \n",
        "    hidden_neurons, \n",
        "    output_neurons,\n",
        "    use_time_distributed=False\n",
        "):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(\n",
        "      hidden_neurons, \n",
        "      input_shape=input_shape, \n",
        "      return_sequences=use_time_distributed\n",
        "  ))\n",
        "  \n",
        "  output = Dense(output_neurons)\n",
        "  if use_time_distributed:\n",
        "    output = TimeDistributed(output)    \n",
        "  \n",
        "  model.add(output)\n",
        "  \n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  show(model)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(model, X, y, epochs, batch_size):\n",
        "  history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "  loss = history.history['loss'][-1]\n",
        "  print(f'Loss: {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI56g27eFWLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Preparando datos (input/output data)"
      ]
    },
    {
      "metadata": {
        "id": "8nR1GABiFWLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero generamos una array de 5 valores:"
      ]
    },
    {
      "metadata": {
        "id": "3NayPah_FWLq",
        "colab_type": "code",
        "outputId": "5c344566-d0a0-42bf-9b9e-163fb7160d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = 5\n",
        "sequence = array([index/float(length) for index in range(length)])\n",
        "print(f'Seq: {sequence}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq: [0.  0.2 0.4 0.6 0.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGbIoYBZFWLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, como este ejemplo es un **toy example** la red va a hacer un echo(Eco). Si entra un cero sale un cero y asi sucesivamente. Pero como vamos a entranar una RNN necesitamos que cada ejemplo de input tenga el formato **(N, T, D)**. \n",
        "\n",
        "**LSTM**: Es un RNN con mas memoria que una SimpleRNN, es decir, recuerda secuencias mucho mas largas. \n",
        "\n",
        "¬øQue es **(N, T, D)**?\n",
        "* N: N√∫mero de ejemplos presentados a la red.\n",
        "* T: Es la secuencia de datos que se van a pasar por cada ejemplo N.\n",
        "* D: Es la dimesionalidad de cada elemento en la secuencia. Por ejemplo: En este caso estamos pasando n√∫meros. Un n√∫mero se puede representar con un solo valor D=1, pero hay casos muy comunes donde la representaci√≥n puede cambiar, por ejemplo con palabras.\n",
        "\n",
        "* En este caso tenemos 5 ejemplos: [ 0, 0.2, 0.4, 0.6, 0.8] => N=5.\n",
        "* En general con RNN uno quiere predecir el siguiente valor de una secuencia. Por ejemplo, tengo los ultimos 3(T=3) valores [ 0, 0.2, 0.4] y quiero predecir el siguente(0.6). En nuestro caso la secuencia es T=1 por que solo queremos hacer un eco, por eso no tiene sentido usar RNN en este caso, con una densa seria lo mismo; pero ya aclaramos es solo un ejemplo de juguete.\n",
        "* Cada valor de la secuencia se puede representar con una unica dimensi√≥n, ya que es un n√∫mero. Entonces D=1.\n",
        "\n",
        "Entonces nos quedaria => Input Shape: **(N, T, D)** = (5, 1, 1)\n",
        "\n",
        "¬øY en la salida que le ponemos?\n",
        "\n",
        "La forma de la salida seria (N, D) ya que a la red se le presentan N=5 ejemplos los cuales tiene una dimensi√≥n de 1 valor numerico. Luego a la salida queremos tener los mismo valores que la entrada (por que se hacec un echo).\n",
        "\n",
        "Asi, Output Shape: **(N, D)** = (5, 1)"
      ]
    },
    {
      "metadata": {
        "id": "8hlb457_FWLw",
        "colab_type": "code",
        "outputId": "4e4e68e7-6c27-4741-8989-dce4d7f6ae10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(len(sequence), 1, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(len(sequence), 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (5, 1, 1): [[[0. ]]\n",
            "\n",
            " [[0.2]]\n",
            "\n",
            " [[0.4]]\n",
            "\n",
            " [[0.6]]\n",
            "\n",
            " [[0.8]]]\n",
            "y (5, 1): [[0. ]\n",
            " [0.2]\n",
            " [0.4]\n",
            " [0.6]\n",
            " [0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rbrdeTaPFWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos los parametros de la red"
      ]
    },
    {
      "metadata": {
        "id": "3t2il7BdFWL1",
        "colab_type": "code",
        "outputId": "4cbf74ee-eaa8-48be-bb96-ff41deb86b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(1,1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 5\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (1, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 5\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-C-Su3gdwEeu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  ¬øPor que input_shape=(1,1)?\n",
        "\n",
        "input_shape es la forma que tiene cada ejemplo en la entrada de la capa. En este caso cada ejemplo\n",
        "tiene una secuencia de T=1  y cada valor tiene una dimensionalidad de D=1.\n",
        "\n",
        "input_shape=**(T, D)**\n",
        "\n",
        "####  ¬øPorque hidden_neurons = 5?\n",
        "\n",
        "En realidad este n√∫mero no tiene ninguna relacion con el N=5. No la busquen por que no la hay!. El n√∫mero de neuronas ocultas es arbitrario, se elige lo que mejor funciona, pero: \n",
        "\n",
        "¬øHay alguna forma de elegir el menor n√∫mero de neuronas que minimize el n√∫mero de parametros de la red?\n",
        "\n",
        "Al parecer hay una forma de calcularlo pero es una aproximaci√≥n, una gu√≠a:\n",
        "\n",
        ">ùëÅ‚Ñé=ùëÅùë† / (ùõº‚àó(ùëÅùëñ+ùëÅùëú))\n",
        "\n",
        "Donde:\n",
        "* ùëÅh : Es lo que  queremos averiguar, el n√∫mero de neuronas de la capa oculta de la LSTM. \n",
        "* ùëÅi : El n√∫mero de neuronas de entrada (Que seria el tama√±o de la secuencia T)\n",
        "* ùëÅo : El n√∫mero de neuronas de salida/ocultas.\n",
        "* ùëÅùë† : El n√∫mero de ejemplos de entrenamiento (En nuestro ejemplo es N=5). \n",
        "* ùõº : Es un factor de escala arbitrario entre 2 y 10.\n",
        "\n",
        "Pero mas alla de esta explicaci√≥n: ** No hay reglas claras para elegir el n√∫mero de neuronas ocultas, es algo que se descubre con prueba y error y depeden del problema a resolver.**\n",
        "\n",
        "[Ver Referencia](https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm)\n",
        "\n",
        "####  ¬øPor que output_neurons=1?\n",
        "\n",
        "Como hablamos, se ingresar cada valor por separado y tenemos un solo valor de salida, por eso tenemos una nerona de salida. Cada salida representa un valor.\n",
        "\n",
        "####  ¬øPor que batch_size=5?\n",
        "\n",
        "Sabemos que una LSTM tiene estado pero tambien sabemos que keras por defecto resetea el estado por cada ejemplo. Es decir que cuando termina de evaluar un ejemplo se resetea el estado. Esto es asi por que el valor por defecto es statefull=False. Ahora, podriamos pensar que con un barch_size=1 es lo mismo que barch_size=5, pero no nos olvidemos que el gradiente descendente se calcula para todos los ejemplos del batch.  Cuanto mas grande el batch_size, mas exacto el calculo del gradiente, asi que en este caso seria mejor batch_size=5.\n",
        "\n",
        "####  ¬øPor que epochs=1000?\n",
        "\n",
        "Esto es arbitrario, pero la regla es elegir el menor n√∫mero de epochs para el cual se llegue al resultado esperado. Es decir, en este caso con 1000 epochs el resultado es el esperado. Si elegimos 10.000 estamos mejorando el error, ¬øPero es necesario? ¬øEl resultado no seria el mismo?"
      ]
    },
    {
      "metadata": {
        "id": "ei3BnQxKFWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create LSTM"
      ]
    },
    {
      "metadata": {
        "id": "NTBKQA6zFWL6",
        "colab_type": "code",
        "outputId": "1c21d2a1-f238-4d91-d2e4-99c626a83876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 255.00 211.00\" width=\"255pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 251,-207 251,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140692574073688 -->\n<g class=\"node\" id=\"node1\">\n<title>140692574073688</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 247,-129.5 247,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"51\" y=\"-102.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"102,-83.5 102,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"131\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"102,-106.5 160,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"131\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"160,-83.5 160,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-114.3\">(None, 1, 1)</text>\n<polyline fill=\"none\" points=\"160,-106.5 247,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140692574076488 -->\n<g class=\"node\" id=\"node2\">\n<title>140692574076488</title>\n<polygon fill=\"none\" points=\"5,-.5 5,-46.5 242,-46.5 242,-.5 5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"58.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"112,-.5 112,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"112,-23.5 170,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"170,-.5 170,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"170,-23.5 242,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140692574073688&#45;&gt;140692574076488 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140692574073688-&gt;140692574076488</title>\n<path d=\"M123.5,-83.3799C123.5,-75.1745 123.5,-65.7679 123.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"127.0001,-56.784 123.5,-46.784 120.0001,-56.784 127.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140692574075312 -->\n<g class=\"node\" id=\"node3\">\n<title>140692574075312</title>\n<polygon fill=\"none\" points=\"59,-166.5 59,-202.5 188,-202.5 188,-166.5 59,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-180.8\">140692574075312</text>\n</g>\n<!-- 140692574075312&#45;&gt;140692574073688 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140692574075312-&gt;140692574073688</title>\n<path d=\"M123.5,-166.4092C123.5,-158.4308 123.5,-148.795 123.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"127.0001,-139.5333 123.5,-129.5333 120.0001,-139.5334 127.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FxeJhdjCFWL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train LSTM"
      ]
    },
    {
      "metadata": {
        "id": "6nWu306BFWMA",
        "colab_type": "code",
        "outputId": "6c214fa0-939a-4714-d714-d1f87c269ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Loss: 0.00013811745156999677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Dz1EE6AFWME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "_zOaRVVeFWMF",
        "colab_type": "code",
        "outputId": "5d89844e-90b0-4689-ad03-6b0ebbc2d72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X]\n",
        "outputs = [\"%.1f\" % output for output in predictions]\n",
        "\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSl2ErvHvtiJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many to One\n",
        "\n",
        "En este caso la idea es tener en la entradas y salida la secuencia completa. De esta manera todo se computa en un solo paso a diferencia del caso anterior."
      ]
    },
    {
      "metadata": {
        "id": "OEQoNwdDZNwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dimensionalidad de entrada\n",
        "\n",
        "* N=1:  Si pasamos la secuencia completa en un solo paso, vamos a tener un solo ejemplo.\n",
        "* T=5: Este unico ejemplo tiene una secuencia (temporal) de tama√±o 5.\n",
        "* D=1: La dimensionalidad de cada elemento de la secuenca no cambia, por que seguimos trabajando con n√∫meros, que se pueden representar en un solo valor como hablamos anteriormente.\n",
        "\n",
        "=> **(N, T, D)** = (1, 5, 1)\n",
        "\n",
        "### Dimensionalidad de salida\n",
        "\n",
        "=> **(N, T)** = (1, 5)\n",
        "\n",
        "* N=1: Solo hay un ejemplo, por lo tanto habra un solo resultados a la salida.\n",
        "* T=5. Cada elemento de salida tiene 5 valores, uno por cada elemento en la secuencia de entrada.\n",
        "\n",
        "\n",
        "Una cosa a tener en cuenta es que N es **variable**! Es la cantidad de ejemplos que le pasamos a la red para entrenar. Osea, podriamos pasar mas o menos ejemplos. \n",
        "Por esta cuestion cuando hacemos model.summary() N aparece como **None**.Se refiere a que dimensi√≥n no esta definida. Osea, la red no tiene una restricci√≥n en el n√∫mero de ejemplos a pasar. N es 1 para este ejemplo, por que no tenemos mas datos."
      ]
    },
    {
      "metadata": {
        "id": "S2KrIEj2ZMGF",
        "colab_type": "code",
        "outputId": "a1b12343-c9e8-4c08-f9be-4c3ec2019a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5): [[0.  0.2 0.4 0.6 0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXBaN4spgBvj",
        "colab_type": "code",
        "outputId": "66431641-71bf-4ab6-9ac5-21de7eb4c912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 5\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 500\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 5\n",
            "batch_size: 1\n",
            "epochs: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZaOf4xqGkzwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buen aca cambiaron alguna cosas:\n",
        "\n",
        "#### ¬øPorque input_shape=(5, 1)?\n",
        " \n",
        "En este caso cada ejemplo tiene una secuenca de 5 valores y cada valor una dimensi√≥n 1.\n",
        "\n",
        "#### ¬øPor que 5 neuronas ocultas?\n",
        "\n",
        "Como ya aclaramos en el caso anterior, este n√∫mero es arbrario, se elije lo que mejor fucione, buscando el n√∫mero mas bajo con el cual se tenga buenos resultados.\n",
        "\n",
        "#### ¬øPor que 5 neuronas de salida?\n",
        "\n",
        "Bueno, la idea es ingresar un ejemplo con una secuencia de 5 valores y a la salida tener un eco de estos mismo 5 valores, asi que necesitamos 5 salidas. Cabe aclarar que si no se usa **return_sequences** la red siempre tiene una unica salida, que es la salida de la ultima celda. ¬øPero por que 5 entonces? Por que esta salida tiene mas de una dimensi√≥n. Las salidas de una LSTM tiene dimensi√≥n igual al n√∫mero de neuronas ocultas. Asi que ojo con esto!, la salida es una sola pero de dimensi√≥n 5.\n",
        "\n",
        "####  ¬øPor que batch_size=1?\n",
        "\n",
        "No nos olvidemos que estamos trabajando con redes neuronales recurrentes. Como sabemos, estas infieren la salida por que recuerdan entradas anteriores, ya que poseen una memoria que puede ser mayor o menor, dependiendo de la implementaci√≥n que usemos (LSTM, SimpleRNN, GRU, etc...).\n",
        "\n",
        "Ahora bien, para tener memoria, la red tiene un estado. Al momento de entrenar la red podemos elegir cuando resetear este estado. Por defecto, Keras resetea el estado luego de procesar cada secuencia. Es posible modificar este comportamiento mediante el parametro **statefull**.\n",
        "\n",
        "* stateful = True :  Guarda el estado de cada sample del batch para luego continuar con ese estado en el proximo batch. Osea, se conserva el estado de cada Xi del batch actual y luego en el siguente batch se restaura ese estado en el element Xi. De esta manera vemos que no se puede usar shuffle ya que es necesario que los ejemplos esten ordenados, de lo contrario estariamos mezclando el estado de un ejemplo con el de otro.\n",
        "* stateful = False: Es el valor por defecto y en este caso el estado se resetea en cada secuencia.\n",
        "\n",
        "Entonces si el modelo es stateless, se reseta el estado de las celas por cada secuencia. Si el modelo es statefull se propaga el estado al siguente batch. Esto significa que el estado del sample Xi en el batch actual se va a usar como estado inicial en el sample Xi2  = Xi + batch_size en el siguiente batch, por esto no hay que usar shuffle ya que perderiamos esta correlaci√≥n.\n",
        "\n",
        "Tambien tengamos en cuenta que Keras aloca un array de estados de size igual al n√∫mero de celdas que tiene la LSTM (output_dim). \n",
        "\n",
        "En modo  stateless,  luego de procesar cada secuencia este array se resetea. En modo statefull, Keras propaga el estado de cada ejemplo entre batches. Entonces, el ejemplo i del batch 1 (Xi+bs) conocera el estado del ejemplo i del batch 0 (Xi). En este caso, la estructura donde se gardan los estados tiene la forma (batch_size, output_dim). \n",
        "\n",
        "Volviendo, en este caso no nos interesa que se conserve el estado entre ejemplos. por eso no se paso statefull=True. Ademas el bach_size es 1 por que tenenos un solo ejemplo.\n",
        "\n",
        "[Ver Referencia](http://philipperemy.github.io/keras-stateful-lstm/)\n",
        "\n",
        "####  ¬øPor que epochs=500?\n",
        "\n",
        "Bueno en este caso como se le pasa toda la secuencia a la red necesitamenos iteraciones para llegar al resultado esperado."
      ]
    },
    {
      "metadata": {
        "id": "uTzY13KIflfk",
        "colab_type": "code",
        "outputId": "453eb617-17fe-46bb-ddfe-81eb4aaf5d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 30        \n",
            "=================================================================\n",
            "Total params: 170\n",
            "Trainable params: 170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 255.00 211.00\" width=\"255pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 251,-207 251,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140692562879880 -->\n<g class=\"node\" id=\"node1\">\n<title>140692562879880</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 247,-129.5 247,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"51\" y=\"-102.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"102,-83.5 102,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"131\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"102,-106.5 160,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"131\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"160,-83.5 160,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"160,-106.5 247,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140692562881560 -->\n<g class=\"node\" id=\"node2\">\n<title>140692562881560</title>\n<polygon fill=\"none\" points=\"5,-.5 5,-46.5 242,-46.5 242,-.5 5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"58.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"112,-.5 112,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"112,-23.5 170,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"170,-.5 170,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"170,-23.5 242,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 140692562879880&#45;&gt;140692562881560 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140692562879880-&gt;140692562881560</title>\n<path d=\"M123.5,-83.3799C123.5,-75.1745 123.5,-65.7679 123.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"127.0001,-56.784 123.5,-46.784 120.0001,-56.784 127.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140692562880664 -->\n<g class=\"node\" id=\"node3\">\n<title>140692562880664</title>\n<polygon fill=\"none\" points=\"59,-166.5 59,-202.5 188,-202.5 188,-166.5 59,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-180.8\">140692562880664</text>\n</g>\n<!-- 140692562880664&#45;&gt;140692562879880 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140692562880664-&gt;140692562879880</title>\n<path d=\"M123.5,-166.4092C123.5,-158.4308 123.5,-148.795 123.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"127.0001,-139.5333 123.5,-129.5333 120.0001,-139.5334 127.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TadUYYubxGuX",
        "colab_type": "code",
        "outputId": "fa775dbe-6a8c-44ea-f7f8-e64e9671e72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.071276400921306e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtGcPhlLyFaS",
        "colab_type": "code",
        "outputId": "fb14184e-fadf-4225-dfce-8efd462f11ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['-0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnVqsPT6z628",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conclusiones hasta el momento\n",
        "\n",
        "Hasta ac√°, podemos ver que la cantidad de parametros de la LSMT no cambio. Entonces, si cambio el tama√±o de la secuencia en una LSTM, no cambia el n√∫mero de sus hiperparametros, lo cual es un **punto positivo**. \n",
        "\n",
        "Por otro lado, podemos ver que la capa densa de salida cambio. Ahora tenemos mas parametros: 29 pesos + 1 bias.\n",
        "\n",
        "Otro tema a tener en cuenta, es que podriamos haber usado una densa es vez de una LSTM, ya que en este ejemplo no estamos usando la memoria que tiene la LSTM entre ejemplos. con una densa de 5 entradas era suficiente.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZDIEb9FZ2HfV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many-to-Many   con la capa wrapper TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "Hj3JvKWx2Gb5",
        "colab_type": "code",
        "outputId": "d5553699-e55e-40ae-f537-d4bcc23f8541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5, 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rn5OCbBt2YVg",
        "colab_type": "code",
        "outputId": "3aed463f-7972-4982-a2e6-82c51906a493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 1\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJWnMtWb3qUv",
        "colab_type": "code",
        "outputId": "de014266-607f-4bdf-a9e7-738579a6d900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons, use_time_distributed=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 5, 5)              140       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 5, 1)              6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 479.00 211.00\" width=\"479pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 475,-207 475,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140692477667928 -->\n<g class=\"node\" id=\"node1\">\n<title>140692477667928</title>\n<polygon fill=\"none\" points=\"112,-83.5 112,-129.5 359,-129.5 359,-83.5 112,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-102.8\">lstm_3: LSTM</text>\n<polyline fill=\"none\" points=\"214,-83.5 214,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"214,-106.5 272,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"272,-83.5 272,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"272,-106.5 359,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-91.3\">(None, 5, 5)</text>\n</g>\n<!-- 140692466315104 -->\n<g class=\"node\" id=\"node2\">\n<title>140692466315104</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 471,-46.5 471,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-19.8\">time_distributed_1(dense_3): TimeDistributed(Dense)</text>\n<polyline fill=\"none\" points=\"326,-.5 326,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"326,-23.5 384,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"384,-.5 384,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-31.3\">(None, 5, 5)</text>\n<polyline fill=\"none\" points=\"384,-23.5 471,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-8.3\">(None, 5, 1)</text>\n</g>\n<!-- 140692477667928&#45;&gt;140692466315104 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140692477667928-&gt;140692466315104</title>\n<path d=\"M235.5,-83.3799C235.5,-75.1745 235.5,-65.7679 235.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"239.0001,-56.784 235.5,-46.784 232.0001,-56.784 239.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140692553571352 -->\n<g class=\"node\" id=\"node3\">\n<title>140692553571352</title>\n<polygon fill=\"none\" points=\"171,-166.5 171,-202.5 300,-202.5 300,-166.5 171,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-180.8\">140692553571352</text>\n</g>\n<!-- 140692553571352&#45;&gt;140692477667928 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140692553571352-&gt;140692477667928</title>\n<path d=\"M235.5,-166.4092C235.5,-158.4308 235.5,-148.795 235.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"239.0001,-139.5333 235.5,-129.5333 232.0001,-139.5334 239.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "duRHbLHY62NL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bueno aca hay varias cosas nuevas:\n",
        "\n",
        "1. use_time_distributed=True: Este parametro esta haciendo dos cosas muy importante al momento de construir el modelo:\n",
        "  * Primero configura la capa LSTM para que retorne todas las salidad de la red(return_sequences=True), una salida por cada celda. Recordemos que una LSTM tiene una salida por cada elemento de la secuencia de entreada. Si tenemos una secuencia de 5, tenemos 5 celdas en la red y cada una tiene una salida. En este caso la LSTM tiene 5 entradas y 5 salidas. Luego, cada salida tiene la dimensi√≥n igual al n√∫mero de neuronas ocultas, que en este caso es 5. Cabe destacar que  con return_sequences=False se toma la salida de la ultima celda 5 de la LSTM.\n",
        "  * Segundo, se agrego una capa que envuelve la capa densa de salida. Lo que hace esta capa, es repetirla la capa densa por cada salida de la LSTM, pero con la condici√≥n de que los pesos se compartan entre todas las densas. Es decir que si la secuencia es de 100 en vez de 5 , la cantidad de p√°rametro no cambia, **otro punto positivo**.\n",
        " \n",
        "2. El n√∫mero de salidas que elegimos para la capa densa era 1, pero se puede ver que al usar la capa TimeDistributed se modifico la salida, ya que al tener una densa por cada salida de la LSTM, ahora la red tiene 5 salida en vez de una.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vQjnCfgQee1K",
        "colab_type": "code",
        "outputId": "7967365c-6cd6-4267-fcfa-5653b06e7685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0007276003598235548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KQ24YKWedlSf",
        "colab_type": "code",
        "outputId": "103d76e1-3c25-41b8-c0ab-8f1013f72f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.1', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ppR_bqyU_lmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusiones finales\n",
        "\n",
        "Ahora que ya vimos todos los ejemplos:\n",
        "\n",
        "* En este √∫ltimo ejemplo tenemos la misma dimensionalidad que el primer, pero a su favor, **permite manejar las secuencias de una forma mas natural que el pimer caso**, donde tenemos que entrenar la red pasando cada valor de la secuencia por separado.\n",
        "\n",
        "* Por otro lado se simplifica la red. El ejemplo many-one  tiene la misma dimensionalidad de entrada y salida que este ultimo ejemplo, pero la diferencia importante es que **bajamos el numero de parametros a entrenar**. Esto se traduce en menor uso de recursos y menor tiempo de entrenamiento."
      ]
    }
  ]
}