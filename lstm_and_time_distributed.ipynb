{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_and_time_distributed.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianmarino/12-RNN/blob/master/lstm_and_time_distributed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DxliPix7Iyr4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando TimeDistributed en una LSTM"
      ]
    },
    {
      "metadata": {
        "id": "EZhlHZXTvhW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One to One"
      ]
    },
    {
      "metadata": {
        "id": "m-jtitj0FWLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2M4jFblFWLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvkTp12bhqli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funciones axiliares\n",
        "\n",
        "La idea es no mostrar código repetido en los ejemplos. Recomiendo analizar estasss funciones  cuando se llegue al momento de utilizarlas.\n"
      ]
    },
    {
      "metadata": {
        "id": "-59ZTMAFGmF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show(model): \n",
        "  model.summary()\n",
        "  dot_mode = model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg')\n",
        "  display(SVG(dot_mode))\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    input_shape, \n",
        "    hidden_neurons, \n",
        "    output_neurons,\n",
        "    use_time_distributed=False\n",
        "):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(\n",
        "      hidden_neurons, \n",
        "      input_shape=input_shape, \n",
        "      return_sequences=use_time_distributed\n",
        "  ))\n",
        "  \n",
        "  output = Dense(output_neurons)\n",
        "  if use_time_distributed:\n",
        "    output = TimeDistributed(output)    \n",
        "  \n",
        "  model.add(output)\n",
        "  \n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  show(model)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(model, X, y, epochs, batch_size):\n",
        "  history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "  loss = history.history['loss'][-1]\n",
        "  print(f'Loss: {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI56g27eFWLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Preparando datos (input/output data)"
      ]
    },
    {
      "metadata": {
        "id": "8nR1GABiFWLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero generamos una array de 5 valores:"
      ]
    },
    {
      "metadata": {
        "id": "3NayPah_FWLq",
        "colab_type": "code",
        "outputId": "d51be0cc-ade8-4372-a71c-204db595a2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = 5\n",
        "sequence = array([index/float(length) for index in range(length)])\n",
        "print(f'Seq: {sequence}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq: [0.  0.2 0.4 0.6 0.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGbIoYBZFWLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, como este ejemplo es un **toy example** la red va a hacer un echo(Eco). Si entra un cero sale un cero y asi sucesivamente. Pero como vamos a entranar una RNN necesitamos que cada ejemplo de input tenga el formato **(N, T, D)**. \n",
        "\n",
        "**LSTM**: Es un RNN con mas memoria que una SimpleRNN, es decir, recuerda secuencias mucho mas largas. \n",
        "\n",
        "¿Que es **(N, T, D)**?\n",
        "* N: Número de ejemplos presentados a la red.\n",
        "* T: Es la secuencia de datos que se van a pasar por cada ejemplo N.\n",
        "* D: Es la dimesionalidad de cada elemento en la secuencia. Por ejemplo: En este caso estamos pasando números. Un número se puede representar con un solo valor D=1, pero hay casos muy comunes donde la representación puede cambiar, por ejemplo con palabras.\n",
        "\n",
        "* En este caso tenemos 5 ejemplos: [ 0, 0.2, 0.4, 0.6, 0.8] => N=5.\n",
        "* En general con RNN uno quiere predecir el siguiente valor de una secuencia. Por ejemplo, tengo los ultimos 3(T=3) valores [ 0, 0.2, 0.4] y quiero predecir el siguente(0.6). En nuestro caso la secuencia es T=1 por que solo queremos hacer un eco, por eso no tiene sentido usar RNN en este caso, con una densa seria lo mismo; pero ya aclaramos es solo un ejemplo de juguete.\n",
        "* Cada valor de la secuencia se puede representar con una unica dimensión, ya que es un número. Entonces D=1.\n",
        "\n",
        "Entonces nos quedaria => Input Shape: **(N, T, D)** = (5, 1, 1)\n",
        "\n",
        "¿Y en la salida que le ponemos?\n",
        "\n",
        "La forma de la salida seria (N, D) ya que a la red se le presentan N=5 ejemplos los cuales tiene una dimensión de 1 valor numerico. Luego a la salida queremos tener los mismo valores que la entrada (por que se hacec un echo).\n",
        "\n",
        "Asi, Output Shape: **(N, D)** = (5, 1)"
      ]
    },
    {
      "metadata": {
        "id": "8hlb457_FWLw",
        "colab_type": "code",
        "outputId": "909ac21e-a83b-432a-9d42-42c298511ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(len(sequence), 1, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(len(sequence), 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (5, 1, 1): [[[0. ]]\n",
            "\n",
            " [[0.2]]\n",
            "\n",
            " [[0.4]]\n",
            "\n",
            " [[0.6]]\n",
            "\n",
            " [[0.8]]]\n",
            "y (5, 1): [[0. ]\n",
            " [0.2]\n",
            " [0.4]\n",
            " [0.6]\n",
            " [0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rbrdeTaPFWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos los parametros de la red"
      ]
    },
    {
      "metadata": {
        "id": "3t2il7BdFWL1",
        "colab_type": "code",
        "outputId": "09481db4-2ed1-4523-8755-fba67bf633c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(1,1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 5\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (1, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 5\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-C-Su3gdwEeu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  ¿Por que input_shape=(1,1)?\n",
        "\n",
        "input_shape es la forma que tiene cada ejemplo en la entrada de la capa. En este caso cada ejemplo\n",
        "tiene una secuencia de T=1  y cada valor tiene una dimensionalidad de D=1.\n",
        "\n",
        "input_shape=**(T, D)**\n",
        "\n",
        "####  ¿Porque hidden_neurons = 5?\n",
        "\n",
        "En realidad este número no tiene ninguna relacion con el N=5. No la busquen por que no la hay!. El número de neuronas ocultas es arbitrario, se elige lo que mejor funciona, pero: \n",
        "\n",
        "¿Hay alguna forma de elegir el menor número de neuronas que minimize el número de parametros de la red?\n",
        "\n",
        "Al parecer hay una forma de calcularlo pero es una aproximación, una guía:\n",
        "\n",
        "> Nh=Ns / (alpha ∗(Ni+No))\n",
        "\n",
        "Donde:\n",
        "* Nh : Es lo que  queremos averiguar, el número de neuronas de la capa oculta de la LSTM. \n",
        "* Ni : El número de neuronas de entrada (Que seria el tamaño de la secuencia T)\n",
        "* No : El número de neuronas de salida/ocultas.\n",
        "* Ns : El número de ejemplos de entrenamiento (En nuestro ejemplo es N=5). \n",
        "* alpha : Es un factor de escala arbitrario entre 2 y 10.\n",
        "\n",
        "Pero mas alla de esta explicación: ** No hay reglas claras para elegir el número de neuronas ocultas, es algo que se descubre con prueba y error y depeden del problema a resolver.**\n",
        "\n",
        "[Ver Referencia](https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm)\n",
        "\n",
        "####  ¿Por que output_neurons=1?\n",
        "\n",
        "Como hablamos, se ingrear cada valor por separado y tenemos un solo valor de salida, por eso tenemos una nerona de salida. Cada salida representa un valor.\n",
        "\n",
        "####  ¿Por que batch_size=5?\n",
        "\n",
        "Sabemos que una LSTM tiene estado pero tambien sabemos que keras por defecto resetea el estado por cada ejemplo. Es decir que cuando termina de evaluar un ejemplo se resetea el estado. Esto es asi por que el valor por defecto es statefull=False. Ahora, podriamos pensar que con un barch_size=1 es lo mismo que barch_size=5, pero no nos olvidemos que el gradiente descendente se calcula para todos los ejemplos del batch.  Cuanto mas grande el batch_size, mas exacto el calculo del gradiente, asi que en este caso seria mejor batch_size=5.\n",
        "\n",
        "####  ¿Por que epochs=1000?\n",
        "\n",
        "Esto es arbitrario, pero la regla es elegir el menor número de epochs para el cual se llegue al resultado esperado. Es decir, en este caso con 1000 epochs el resultado es el esperado. Si elegimos 10.000 estamos mejorando el error, ¿Pero es necesario? ¿El resultado no seria el mismo?"
      ]
    },
    {
      "metadata": {
        "id": "ei3BnQxKFWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create LSTM"
      ]
    },
    {
      "metadata": {
        "id": "NTBKQA6zFWL6",
        "colab_type": "code",
        "outputId": "35e4890c-5373-43a9-9edf-40da618f4ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675215587312 -->\n<g class=\"node\" id=\"node1\">\n<title>140675215587312</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_12: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 1, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140675215588544 -->\n<g class=\"node\" id=\"node2\">\n<title>140675215588544</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_12: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140675215587312&#45;&gt;140675215588544 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675215587312-&gt;140675215588544</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675215587872 -->\n<g class=\"node\" id=\"node3\">\n<title>140675215587872</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">140675215587872</text>\n</g>\n<!-- 140675215587872&#45;&gt;140675215587312 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675215587872-&gt;140675215587312</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FxeJhdjCFWL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train LSTM"
      ]
    },
    {
      "metadata": {
        "id": "6nWu306BFWMA",
        "colab_type": "code",
        "outputId": "080adb93-8437-41b5-a5f2-1f12307b6c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.00020001645316369832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Dz1EE6AFWME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "_zOaRVVeFWMF",
        "colab_type": "code",
        "outputId": "a4e9da22-9a4e-41ca-aec1-a0ae7f8a57ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X]\n",
        "outputs = [\"%.1f\" % output for output in predictions]\n",
        "\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSl2ErvHvtiJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many to One\n",
        "\n",
        "En este caso la idea es tener en la entradas y salida la secuencia completa. De esta manera todo se computa en un solo paso a diferencia del caso anterior."
      ]
    },
    {
      "metadata": {
        "id": "OEQoNwdDZNwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dimensionalidad de entrada\n",
        "\n",
        "* N=1:  Si pasamos la secuencia completa en un solo paso, vamos a tener un solo ejemplo.\n",
        "* T=5: Este unico ejemplo tiene una secuencia (temporal) de tamaño 5.\n",
        "* D=1: La dimensionalidad de cada elemento de la secuenca no cambia, por que seguimos trabajando con números, que se pueden representar en un solo valor como hablamos anteriormente.\n",
        "\n",
        "=> **(N, T, D)** = (1, 5, 1)\n",
        "\n",
        "### Dimensionalidad de salida\n",
        "\n",
        "=> **(N, T)** = (1, 5)\n",
        "\n",
        "* N=1: Solo hay un ejemplo, por lo tanto habra un solo resultados a la salida.\n",
        "* T=5. Cada elemento de salida tiene 5 valores, uno por cada elemento en la secuencia de entrada.\n",
        "\n",
        "\n",
        "Una cosa a tener en cuenta es que N es **variable**! Es la cantidad de ejemplos que le pasamos a la red para entrenar. Osea, podriamos pasar mas o menos ejemplos. \n",
        "Por esta cuestion cuando hacemos model.summary() N aparece como **None**.Se refiere a que dimensión no esta definida. Osea, la red no tiene una restricción en el número de ejemplos a pasar. N es 1 para este ejemplo, por que no tenemos mas datos."
      ]
    },
    {
      "metadata": {
        "id": "S2KrIEj2ZMGF",
        "colab_type": "code",
        "outputId": "4eae3bbe-085a-46e2-9ff1-5084b2e80b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5): [[0.  0.2 0.4 0.6 0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXBaN4spgBvj",
        "colab_type": "code",
        "outputId": "57054f93-842f-4771-b886-a6f9481af8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 5\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 500\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 5\n",
            "batch_size: 1\n",
            "epochs: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZaOf4xqGkzwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buen aca cambiaron alguna cosas:\n",
        "\n",
        "#### ¿Porque input_shape=(5, 1)?\n",
        " \n",
        "En este caso cada ejemplo tiene una secuenca de 5 valores y cada valor una dimensión 1.\n",
        "\n",
        "#### ¿Por que 5 neuronas ocultas?\n",
        "\n",
        "Como ya aclaramos en el caso anterior, este número es arbrario, se elije lo que mejor fucione, buscando el número mas bajo con el cual se tenga buenos resultados.\n",
        "\n",
        "#### ¿Por que 5 neuronas de salida?\n",
        "\n",
        "Bueno, la idea es ingresar un ejemplo con una secuencia de 5 valores y a la salida tener un eco de estos mismo 5 valores, asi que necesitamos 5 salidas. Cabe aclarar que si no se usa **return_sequences** la red siempre tiene una unica salida, que es la salida de la ultima celda. ¿Pero por que 5 entonces? Por que esta salida tiene mas de una dimensión. Las salidas de una LSTM tiene dimensión igual al número de neuronas ocultas. Asi que ojo con esto!, la salida es una sola pero de dimensión 5.\n",
        "\n",
        "####  ¿Por que batch_size=1?\n",
        "\n",
        "No nos olvidemos que estamos trabajando con redes neuronales recurrentes. Como sabemos, estas infieren la salida por que recuerdan entradas anteriores, ya que poseen una memoria que puede ser mayor o menor, dependiendo de la implementación que usemos (LSTM, SimpleRNN, GRU, etc...).\n",
        "\n",
        "Ahora bien, para tener memoria, la red tiene un estado. Al momento de entrenar la red podemos elegir cuando resetear este estado. Por defecto, Keras resetea el estado luego de procesar cada secuencia. Es posible modificar este comportamiento mediante el parametro **statefull**.\n",
        "\n",
        "* stateful = True :  Guarda el estado de cada sample del batch para luego continuar con ese estado en el proximo batch. Osea, se conserva el estado de cada Xi del batch actual y luego en el siguente batch se restaura ese estado en el element Xi. De esta manera vemos que no se puede usar shuffle ya que es necesario que los ejemplos esten ordenados, de lo contrario estariamos mezclando el estado de un ejemplo con el de otro.\n",
        "* stateful = False: Es el valor por defecto y en este caso el estado se resetea en cada secuencia.\n",
        "\n",
        "Entonces si el modelo es stateless, se reseta el estado de las celas por cada secuencia. Si el modelo es statefull se propaga el estado al siguente batch. Esto significa que el estado del sample Xi en el batch actual se va a usar como estado inicial en el sample Xi2  = Xi + batch_size en el siguiente batch, por esto no hay que usar shuffle ya que perderiamos esta correlación.\n",
        "\n",
        "Tambien tengamos en cuenta que Keras aloca un array de estados de size igual al número de celdas que tiene la LSTM (output_dim). \n",
        "\n",
        "En modo  stateless,  luego de procesar cada secuencia este array se resetea. En modo statefull, Keras propaga el estado de cada ejemplo entre batches. Entonces, el ejemplo i del batch 1 (Xi+bs) conocera el estado del ejemplo i del batch 0 (Xi). En este caso, la estructura donde se gardan los estados tiene la forma (batch_size, output_dim). \n",
        "\n",
        "Volviendo, en este caso no nos interesa que se conserve el estado entre ejemplos. por eso no se paso statefull=True. Ademas el bach_size es 1 por que tenenos un solo ejemplo.\n",
        "\n",
        "[Ver Referencia](http://philipperemy.github.io/keras-stateful-lstm/)\n",
        "\n",
        "####  ¿Por que epochs=500?\n",
        "\n",
        "Bueno en este caso como se le pasa toda la secuencia a la red necesita menos iteraciones para llegar al resultado esperado."
      ]
    },
    {
      "metadata": {
        "id": "uTzY13KIflfk",
        "colab_type": "code",
        "outputId": "34e00694-5ec1-47ea-95c7-04a55f2ad077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 30        \n",
            "=================================================================\n",
            "Total params: 170\n",
            "Trainable params: 170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675213137232 -->\n<g class=\"node\" id=\"node1\">\n<title>140675213137232</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_13: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140675204246552 -->\n<g class=\"node\" id=\"node2\">\n<title>140675204246552</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_13: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 140675213137232&#45;&gt;140675204246552 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675213137232-&gt;140675204246552</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675204246776 -->\n<g class=\"node\" id=\"node3\">\n<title>140675204246776</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">140675204246776</text>\n</g>\n<!-- 140675204246776&#45;&gt;140675213137232 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675204246776-&gt;140675213137232</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TadUYYubxGuX",
        "colab_type": "code",
        "outputId": "eb72c330-3697-472f-a0fa-38101eb418f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 4.622968606776516e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtGcPhlLyFaS",
        "colab_type": "code",
        "outputId": "9a6c3a43-9be1-48e0-b70f-368bdb8cb12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['-0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnVqsPT6z628",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conclusiones hasta el momento\n",
        "\n",
        "Hasta acá, podemos ver que la cantidad de parametros de la LSMT no cambio. Entonces, si cambio el tamaño de la secuencia en una LSTM, no cambia el número de sus hiperparametros, lo cual es un **punto positivo**. \n",
        "\n",
        "Por otro lado, podemos ver que la capa densa de salida cambio. Ahora tenemos mas parametros: 29 pesos + 1 bias.\n",
        "\n",
        "Otro tema a tener en cuenta, es que podriamos haber usado una densa es vez de una LSTM, ya que en este ejemplo no estamos usando la memoria que tiene la LSTM entre ejemplos. con una densa de 5 entradas era suficiente.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZDIEb9FZ2HfV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many-to-Many   con la capa wrapper TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "Hj3JvKWx2Gb5",
        "colab_type": "code",
        "outputId": "3e2d752a-22d0-4f3d-de62-940bdc4e32cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5, 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rn5OCbBt2YVg",
        "colab_type": "code",
        "outputId": "fcc7fce9-d466-407c-c6fe-5e1593d0dc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 1\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJWnMtWb3qUv",
        "colab_type": "code",
        "outputId": "9425b386-bf2d-4bd7-a103-64ae81644beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons, use_time_distributed=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_14 (LSTM)               (None, 5, 5)              140       \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 5, 1)              6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 486.00 211.00\" width=\"486pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 482,-207 482,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675191822432 -->\n<g class=\"node\" id=\"node1\">\n<title>140675191822432</title>\n<polygon fill=\"none\" points=\"111.5,-83.5 111.5,-129.5 366.5,-129.5 366.5,-83.5 111.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-102.8\">lstm_14: LSTM</text>\n<polyline fill=\"none\" points=\"221.5,-83.5 221.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"221.5,-106.5 279.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"279.5,-83.5 279.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"279.5,-106.5 366.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-91.3\">(None, 5, 5)</text>\n</g>\n<!-- 140675190476304 -->\n<g class=\"node\" id=\"node2\">\n<title>140675190476304</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 478,-46.5 478,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-19.8\">time_distributed_6(dense_14): TimeDistributed(Dense)</text>\n<polyline fill=\"none\" points=\"333,-.5 333,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"333,-23.5 391,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"391,-.5 391,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-31.3\">(None, 5, 5)</text>\n<polyline fill=\"none\" points=\"391,-23.5 478,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-8.3\">(None, 5, 1)</text>\n</g>\n<!-- 140675191822432&#45;&gt;140675190476304 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675191822432-&gt;140675190476304</title>\n<path d=\"M239,-83.3799C239,-75.1745 239,-65.7679 239,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-56.784 239,-46.784 235.5001,-56.784 242.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675215585968 -->\n<g class=\"node\" id=\"node3\">\n<title>140675215585968</title>\n<polygon fill=\"none\" points=\"174.5,-166.5 174.5,-202.5 303.5,-202.5 303.5,-166.5 174.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-180.8\">140675215585968</text>\n</g>\n<!-- 140675215585968&#45;&gt;140675191822432 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675215585968-&gt;140675191822432</title>\n<path d=\"M239,-166.4092C239,-158.4308 239,-148.795 239,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-139.5333 239,-129.5333 235.5001,-139.5334 242.5001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "duRHbLHY62NL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bueno aca hay varias cosas nuevas:\n",
        "\n",
        "1. use_time_distributed=True: Este parametro esta haciendo dos cosas muy importante al momento de construir el modelo:\n",
        "  * Primero configura la capa LSTM para que retorne todas las salidad de la red(return_sequences=True), una salida por cada celda. Recordemos que una LSTM tiene una salida por cada elemento de la secuencia de entreada. Si tenemos una secuencia de 5, tenemos 5 celdas en la red y cada una tiene una salida. En este caso la LSTM tiene 5 entradas y 5 salidas. Luego, cada salida tiene la dimensión igual al número de neuronas ocultas, que en este caso es 5. Cabe destacar que  con return_sequences=False se toma la salida de la ultima celda 5 de la LSTM.\n",
        "  * Segundo, se agrego una capa que envuelve la capa densa de salida. Lo que hace esta capa, es repetirla la capa densa por cada salida de la LSTM, pero con la condición de que los pesos se compartan entre todas las densas. Es decir que si la secuencia es de 100 en vez de 5 , la cantidad de párametro no cambia, **otro punto positivo**.\n",
        " \n",
        "2. El número de salidas que elegimos para la capa densa era 1, pero se puede ver que al usar la capa TimeDistributed se modifico la salida, ya que al tener una densa por cada salida de la LSTM, ahora la red tiene 5 salida en vez de una.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vQjnCfgQee1K",
        "colab_type": "code",
        "outputId": "ac1ae9ab-740e-4022-8ca0-6a5cab0d2222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0006119798053987324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KQ24YKWedlSf",
        "colab_type": "code",
        "outputId": "3c4c4293-3ec7-48e6-af49-569b6c05a32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ppR_bqyU_lmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusiones finales\n",
        "\n",
        "Ahora que ya vimos todos los ejemplos:\n",
        "\n",
        "* En este último ejemplo tenemos la misma dimensionalidad que el primer, pero a su favor, **permite manejar las secuencias de una forma mas natural que el pimer caso**, donde tenemos que entrenar la red pasando cada valor de la secuencia por separado.\n",
        "\n",
        "* Por otro lado se simplifica la red. El ejemplo many-one  tiene la misma dimensionalidad de entrada y salida que este ultimo ejemplo, pero la diferencia importante es que **bajamos el numero de parametros a entrenar**. Esto se traduce en menor uso de recursos y menor tiempo de entrenamiento."
      ]
    }
  ]
}