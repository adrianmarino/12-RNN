{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_and_time_distributed.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianmarino/12-RNN/blob/master/lstm_and_time_distributed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DxliPix7Iyr4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando TimeDistributed con LSTM's"
      ]
    },
    {
      "metadata": {
        "id": "EZhlHZXTvhW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One to One"
      ]
    },
    {
      "metadata": {
        "id": "m-jtitj0FWLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2M4jFblFWLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvkTp12bhqli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funciones axiliares\n",
        "\n",
        "Estas son funiones para no mostrar código repetido en los ejemplos. Recomiendo analizarlas cuando lleguemos al momento de utilizarlas, ante no por que es tratar de entender las cosas al revéz.\n"
      ]
    },
    {
      "metadata": {
        "id": "-59ZTMAFGmF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show(model): \n",
        "  model.summary()\n",
        "  dot_mode = model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg')\n",
        "  display(SVG(dot_mode))\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    input_shape, \n",
        "    hidden_neurons, \n",
        "    output_neurons,\n",
        "    use_time_distributed=False\n",
        "):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(\n",
        "      hidden_neurons, \n",
        "      input_shape=input_shape, \n",
        "      return_sequences=use_time_distributed\n",
        "  ))\n",
        "  \n",
        "  output = Dense(output_neurons)\n",
        "  if use_time_distributed:\n",
        "    output = TimeDistributed(output)    \n",
        "  \n",
        "  model.add(output)\n",
        "  \n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  show(model)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(model, X, y, epochs, batch_size):\n",
        "  history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "  loss = history.history['loss'][-1]\n",
        "  print(f'Loss: {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI56g27eFWLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Prepare samples (input/output data)"
      ]
    },
    {
      "metadata": {
        "id": "8nR1GABiFWLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero generamos una array de 5 valores:"
      ]
    },
    {
      "metadata": {
        "id": "3NayPah_FWLq",
        "colab_type": "code",
        "outputId": "d51be0cc-ade8-4372-a71c-204db595a2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = 5\n",
        "sequence = array([index/float(length) for index in range(length)])\n",
        "print(f'Seq: {sequence}')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq: [0.  0.2 0.4 0.6 0.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGbIoYBZFWLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, como es un toy example la red va a hacer un echo(Eco), si entra un cero sale un cero y asi sucesivamente. Pero como vamos a entranar una RNN necesitamos que cada ejemplo de input tenga el formato **(N, T, D)**. \n",
        "\n",
        "**LSTM**: Es un RNN con mas memoria que una SimpleRNN, es decir, recuerda secuencias mucho mas largas. \n",
        "\n",
        "¿Pero que es esto?\n",
        "* N: Número de ejemplos presentados a la red.\n",
        "* T: Es la secuencia de datos que se van a pasar por cada ejemplo N.\n",
        "* D: Es la dimesionalidad de cada elemento en la secuencia. Por ejemplo: En este caso estamos pasando números. Un número se puede representar con un solo valor D=1, pero hay casos muy comunes donde la representación puede cambiar, por ejemplo con palabras.\n",
        "\n",
        "* En este caso tenemos 5 ejemplos: [ 0, 0.2, 0.4, 0.6, 0.8] => N=5.\n",
        "* En general con RNN uno quiere predecir el siguiente valor de una secuencia. Por ejemplo, tengo los ultimos 3(T=3) valores [ 0, 0.2, 0.4] y quiero predecir el siguente(0.6). En nuestro caso la secuencia es T=1 por que solo queremos hacer un eco, por eso no tiene sentido usar RNN, con una densa seria lo mismo.\n",
        "* Cada valor de la secuencia se puede representar con una unica dimensión, ya que es un numero. Entonces D=1\n",
        "\n",
        "Input Shape: **(N, T, D)** = (5, 1, 1)\n",
        "\n",
        "¿Y en la salida que le ponemos?\n",
        "\n",
        "la forma de la salida seria (N, D) ya que a la red se le presentan N=5 ejemplos los cuales tiene una dimensión de 1 valor numerico.\n",
        "\n",
        "Output Shape: **(N, D)** = (5, 1)"
      ]
    },
    {
      "metadata": {
        "id": "8hlb457_FWLw",
        "colab_type": "code",
        "outputId": "909ac21e-a83b-432a-9d42-42c298511ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(len(sequence), 1, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(len(sequence), 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (5, 1, 1): [[[0. ]]\n",
            "\n",
            " [[0.2]]\n",
            "\n",
            " [[0.4]]\n",
            "\n",
            " [[0.6]]\n",
            "\n",
            " [[0.8]]]\n",
            "y (5, 1): [[0. ]\n",
            " [0.2]\n",
            " [0.4]\n",
            " [0.6]\n",
            " [0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rbrdeTaPFWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define LSTM configuration"
      ]
    },
    {
      "metadata": {
        "id": "3t2il7BdFWL1",
        "colab_type": "code",
        "outputId": "09481db4-2ed1-4523-8755-fba67bf633c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(1,1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 5\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (1, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 5\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-C-Su3gdwEeu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora analicemos mejorlos parametros:\n",
        "\n",
        "####  ¿Porque 5 neuronas ocultas?\n",
        "\n",
        "En realidad este numero no tiene ninguna relacion con el N=5. no la busquen por que no la hay!. El numero de neuronas ocultas es arbitrario, se elige lo que mejor funciona pero: \n",
        "\n",
        "¿Hay alguna forma de elegir elmenor numero de neuronas que minimize el numero de parametros de la red?\n",
        "\n",
        "Al parecer hay una forma de calcularlo pero es una aplroximación, una guia:\n",
        "\n",
        ">$ 𝑁ℎ=𝑁𝑠 / (𝛼∗(𝑁𝑖+𝑁𝑜))$\n",
        "\n",
        "Donde:\n",
        "* $𝑁h$ = El lo que queremos averiguar, el número de neuronas de oa capa oculata de la LSTM. \n",
        "* $𝑁i$ = El número de neuronas de entrada (Que seria el tamaño de la secuencia T)\n",
        "* $𝑁𝑜$ = El número de neuronas de salida (La dimencionalidad?).\n",
        "* $𝑁𝑠$ = El número de ejemplos de entrenamiento(En nuestro ejemplo es N=5). \n",
        "* $𝛼$ = Es un factor de escala arbitrario entre 2 y 10.\n",
        "\n",
        "Pero mas alla de esta explicación: ** No hay reglas claras para elegir el numero de neuronas acoltas, es algo que se descubre con prueba y error y depeden del problema a resolver.**\n",
        "\n",
        "[Ver Referencia](https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm)\n",
        "\n",
        "####  ¿Por que batch_size=5?\n",
        "\n",
        "Sabemos una LSTM tiene estado pero tambien sabemos qeu keras por defecto resetea estado por cada ejemplo. Es decir que cunado termina de evaluar un ejemplose resetea el estado. Esi es asi por que el valor por defecto del parametro statefull es False. Peso si asi podriamos pensar que con un barch_size=1 es lo mismoque barch_size=5 pero no nos olvidemos que el gradiente descendente se calcula para todos los ejemplos del batch si cunato mas grande el batch_size va a ser ma exacto el calculo, asiq eucreoque ne este caso es mejor batch_size=5.\n",
        "\n",
        "####  ¿Por que una reurona de salida?\n",
        "\n",
        "Como hablamos, que ingrear cada valor por separado y tener un valor de salida por eso tenemos una nerona de salida. Cada salida representa un valor.\n",
        "\n",
        "####  ¿Por que input_shape=(1,1)?\n",
        "\n",
        "input_shapr es la forma que tienecada ejemplo en la entrada de la capa. En caso cada ejemplo\n",
        "tiene una secuencia de 1 valor y cada valor tiene una dimensionalidad de 1.\n",
        "\n",
        "input_shape=**(T, D)**\n",
        "\n",
        "\n",
        "####  ¿Por que epochs=1000?\n",
        "Esto tambien es arbitrario, pero la regla es elegir el menor numero de epochs para el cual se llegue al resultado esperado. \n",
        "Es decir, en este caso con 1000 epochs el resultado es el esperado. Si elegimos 10.000 estamos mejorando el error pero es necesario? El resutlado no seria el mismo?"
      ]
    },
    {
      "metadata": {
        "id": "ei3BnQxKFWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create LSTM"
      ]
    },
    {
      "metadata": {
        "id": "NTBKQA6zFWL6",
        "colab_type": "code",
        "outputId": "35e4890c-5373-43a9-9edf-40da618f4ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675215587312 -->\n<g class=\"node\" id=\"node1\">\n<title>140675215587312</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_12: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 1, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140675215588544 -->\n<g class=\"node\" id=\"node2\">\n<title>140675215588544</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_12: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140675215587312&#45;&gt;140675215588544 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675215587312-&gt;140675215588544</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675215587872 -->\n<g class=\"node\" id=\"node3\">\n<title>140675215587872</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">140675215587872</text>\n</g>\n<!-- 140675215587872&#45;&gt;140675215587312 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675215587872-&gt;140675215587312</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FxeJhdjCFWL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train LSTM"
      ]
    },
    {
      "metadata": {
        "id": "6nWu306BFWMA",
        "colab_type": "code",
        "outputId": "080adb93-8437-41b5-a5f2-1f12307b6c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.00020001645316369832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Dz1EE6AFWME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "_zOaRVVeFWMF",
        "colab_type": "code",
        "outputId": "a4e9da22-9a4e-41ca-aec1-a0ae7f8a57ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X]\n",
        "outputs = [\"%.1f\" % output for output in predictions]\n",
        "\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSl2ErvHvtiJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many to One\n",
        "\n",
        "La idea en este caso es tomar como entradas toda la seguencia y en la salida tener toda la secuencia, todo en un solo paso a diferencia del caso anterior."
      ]
    },
    {
      "metadata": {
        "id": "OEQoNwdDZNwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dimensionalidad de entrada\n",
        "\n",
        "* N=1: Entonces si pasamos la secuencia completa en un solo paso, vamos a tener un solo ejemplo.\n",
        "* T=5: Este unico ejemplo tiene una secuencia (temporal) de tamaño 5.\n",
        "* D=1: La dimencionalidad del cada elemento de la secuenca no cambia, por que seguimos trabajando con numeros que se pueden representar en un solo valor ,como hablamos anteriormente.\n",
        "\n",
        "=> **(N, T, D)** = (1, 5, 1)\n",
        "\n",
        "### Dimensionalidad de salida\n",
        "\n",
        "=> **(N, T)** = (1, 5)\n",
        "\n",
        "* N=1: Solo hay un ejemplo, por o tanto habra un solo resultados a la salida.\n",
        "*T=5. Cada elemento de salida tiene 5 valores, uno por cada elemento en la secuencia de entrada.\n",
        "\n",
        "\n",
        "Una cosa a tener en cuenta es que N es *variable**! Es la cantidad de ejemplos que le pasamos a la red para entrenar. Osea, podriamos pasar mas o menos ejemplos. \n",
        "Por esta cuestion cuando hacemos model.summary() N aparece como **None**.Se refiere a que dimensión no esta definida. Osea, la red no tiene una restricción en el número de ejemplos a pasar. N es 1 para este ejemplo, por que no tenemos mas datos."
      ]
    },
    {
      "metadata": {
        "id": "S2KrIEj2ZMGF",
        "colab_type": "code",
        "outputId": "4eae3bbe-085a-46e2-9ff1-5084b2e80b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5): [[0.  0.2 0.4 0.6 0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXBaN4spgBvj",
        "colab_type": "code",
        "outputId": "57054f93-842f-4771-b886-a6f9481af8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 5\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 500\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 5\n",
            "batch_size: 1\n",
            "epochs: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZaOf4xqGkzwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buen aca cambiaron alguna cosas:\n",
        "\n",
        "#### ¿Porque input_shape=(5, 1)?\n",
        " \n",
        "En este caso cada ejemplo tiene una secuenca de 5 valores y cada valor una dimensión 1.\n",
        "\n",
        "#### ¿Por que 3 neuronas ocultas?\n",
        "\n",
        "Como ya aclaramos en el caso anterior, este numero es arbrario, se elije lo que mejor fucione, pero buscando el número mas bajo con el cual se tenga buenos resultados.\n",
        "\n",
        "#### ¿Por que 5 neuronas de salida?\n",
        "\n",
        "Bueno, la idea es ingresar un ejemplo con una secuencia de 5 valores y a la salida tener un eco de estos mismo 5 valores, asi que necesitamos 5 salidas.\n",
        "\n",
        "####  ¿Por que batch_size=1?\n",
        "\n",
        "No nos olvidemos que estamos trabajando con redes neuronales recurrentes. Como sabemos, estas infieren la salida por que recuerdan entradas anteriores, ya que poseen una memoria que puede ser mayor o menor, dependiendo de la implementación que usemos (LSTM, SimpleRNN, GRU, etc...).\n",
        "\n",
        "Ahora bien, para tener memoria, la red tiene un estado. Al momento de entranar la red podemos elegir cuando resetear este estado. Por defecto, Keras resetea el estado luego de procesar cada secuencia. Es posible modificar este comportamiento mediante el parametro **statefull**.\n",
        "\n",
        "* stateful = True :  Guarda el estado de cada sample del batch para luego continuar con ese estado en el proximo batch. Osea, se conserva el estado de cada Xi del batch actual y luego en el siguente batch se restaura ese estado en el element Xi. De esta manera vemos que no se puede usar shuffle ya que es necesario que los ejemplos esten ordenados, de lo contrario estariamos mezclando el estado de un ejemplo con el de otro.\n",
        "* stateful = False: Es el valor por defecto y en este caso el estado se resetea en cada secuencia.\n",
        "\n",
        "Entonces si el modelo es stateless, se resete el estado de las celas por cada secuencia. Si el modelo es statefull se propaga el estado al siguente batch. Esto significa que el estado del sample Xi en el batch actual se va a usar como estado inicial en el sample Xi2  = Xi + batch_size en el siguiente batch, por esto no hay que usar shuffle ya que perderiamos esta correlación.\n",
        "\n",
        "Por otro lado cuando el modelo es stateless, Keras aloca un array de estados de size igual al numero de celdas que tiene la LSTM (output_dim). Luego de procesar cada secuencia este array se resetea.\n",
        "\n",
        "En modo statefull, Keras propaga el estado de cada ejemplo entre batches. Entonces, el ejemplo i del batch 1 (Xi+bs) conocera el estado del ejemplo i del batch 0 (Xi). En este caso, la estructora donde se gardan los estados tiene la forma (batch_size, output_dim). Esta es la razon por la cual keras te fuerza a especificar el batch_size cuando se crea la capa LSTM en modo statefull.\n",
        "Volviendo, en este caso no nos interesa que se conserve el estado entre ejemplos por eso no se paso statefull=True. Ademas el bach_size es 1 por que tenenos un solo ejemplo.\n",
        "\n",
        "[Ver Referencia](http://philipperemy.github.io/keras-stateful-lstm/)\n",
        "\n",
        "####  ¿Por que epochs=500?\n",
        "\n",
        "Bueno en este caso como se le pasa toda la secuencia a la red necesitamenos iteraciones para llegar al resultado esperado."
      ]
    },
    {
      "metadata": {
        "id": "uTzY13KIflfk",
        "colab_type": "code",
        "outputId": "34e00694-5ec1-47ea-95c7-04a55f2ad077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 30        \n",
            "=================================================================\n",
            "Total params: 170\n",
            "Trainable params: 170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675213137232 -->\n<g class=\"node\" id=\"node1\">\n<title>140675213137232</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_13: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140675204246552 -->\n<g class=\"node\" id=\"node2\">\n<title>140675204246552</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_13: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 140675213137232&#45;&gt;140675204246552 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675213137232-&gt;140675204246552</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675204246776 -->\n<g class=\"node\" id=\"node3\">\n<title>140675204246776</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">140675204246776</text>\n</g>\n<!-- 140675204246776&#45;&gt;140675213137232 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675204246776-&gt;140675213137232</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TadUYYubxGuX",
        "colab_type": "code",
        "outputId": "eb72c330-3697-472f-a0fa-38101eb418f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 4.622968606776516e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtGcPhlLyFaS",
        "colab_type": "code",
        "outputId": "9a6c3a43-9be1-48e0-b70f-368bdb8cb12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['-0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnVqsPT6z628",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Conclusiones hasta el momento\n",
        "\n",
        "Hasta acá, podemos ver la cantidad de parametros de la LSMT no cambio. Osea, que si cambio el tamaño de la secuencia en una LSTM no cambia el número de sus hiperparametros, lo cual es un punto positivo. \n",
        "\n",
        "Por otro lado, podemos ver que la capa densa de salida si cambio. Ahora tenemos mas parametros a entrenar: 29 pesos + un bias.\n",
        "\n",
        "Otro tema a tener en cuenta, es que podriamos haber usado una cadadensa es vez de una LSTM, ya que en este ejemplo no estamos usando la memoria que tiene la LSTM entre ejemplos. con una densa de 5 entradas era suficiente.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZDIEb9FZ2HfV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many-to-Many con wrapper TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "Hj3JvKWx2Gb5",
        "colab_type": "code",
        "outputId": "3e2d752a-22d0-4f3d-de62-940bdc4e32cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5, 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rn5OCbBt2YVg",
        "colab_type": "code",
        "outputId": "fcc7fce9-d466-407c-c6fe-5e1593d0dc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 5\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 5\n",
            "output_neurons: 1\n",
            "batch_size: 1\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJWnMtWb3qUv",
        "colab_type": "code",
        "outputId": "9425b386-bf2d-4bd7-a103-64ae81644beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons, use_time_distributed=True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_14 (LSTM)               (None, 5, 5)              140       \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 5, 1)              6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 486.00 211.00\" width=\"486pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 482,-207 482,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140675191822432 -->\n<g class=\"node\" id=\"node1\">\n<title>140675191822432</title>\n<polygon fill=\"none\" points=\"111.5,-83.5 111.5,-129.5 366.5,-129.5 366.5,-83.5 111.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-102.8\">lstm_14: LSTM</text>\n<polyline fill=\"none\" points=\"221.5,-83.5 221.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"221.5,-106.5 279.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"279.5,-83.5 279.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"279.5,-106.5 366.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-91.3\">(None, 5, 5)</text>\n</g>\n<!-- 140675190476304 -->\n<g class=\"node\" id=\"node2\">\n<title>140675190476304</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 478,-46.5 478,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-19.8\">time_distributed_6(dense_14): TimeDistributed(Dense)</text>\n<polyline fill=\"none\" points=\"333,-.5 333,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"333,-23.5 391,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"391,-.5 391,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-31.3\">(None, 5, 5)</text>\n<polyline fill=\"none\" points=\"391,-23.5 478,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-8.3\">(None, 5, 1)</text>\n</g>\n<!-- 140675191822432&#45;&gt;140675190476304 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140675191822432-&gt;140675190476304</title>\n<path d=\"M239,-83.3799C239,-75.1745 239,-65.7679 239,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-56.784 239,-46.784 235.5001,-56.784 242.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140675215585968 -->\n<g class=\"node\" id=\"node3\">\n<title>140675215585968</title>\n<polygon fill=\"none\" points=\"174.5,-166.5 174.5,-202.5 303.5,-202.5 303.5,-166.5 174.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-180.8\">140675215585968</text>\n</g>\n<!-- 140675215585968&#45;&gt;140675191822432 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140675215585968-&gt;140675191822432</title>\n<path d=\"M239,-166.4092C239,-158.4308 239,-148.795 239,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-139.5333 239,-129.5333 235.5001,-139.5334 242.5001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "duRHbLHY62NL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bueno aca hay varias cosas nuevas:\n",
        "\n",
        "1. use_time_distributed=True: Este parametro esta haciendo dos cosas muy importante al momento de construir el modelo:\n",
        "  * Primero configura la capa LSTM para que retorne todas las salidad de la red(return_sequences=True) . Recordemos que un LSTM tiene una salida por cada elemento de la secuencia de entreada. Si tenemos una secuencia de 5, tenemos 5 steps en la red y cada uno tiene una salida. En este caso entonces la LSTM tiene 5 entradas y 5 salidas. Luego, cada salida tiene la dimensión igual al número de neuronas ocultas, que en este caso es 3. Cabe destacar que  con return_sequences=False se toma la salida del step 5 (último) de la LSTM.\n",
        "  * Segundo, se agrego una capa que envuelve(wrapea) la capa densa de salida. Lo que hace esta capa, es repetirla la capa densa por cada salida de la LSTM, pero con la condición de que los pesos de la densa se compartan entre todas las salida. Es decir que si la secuencia de 100 en vez de 5 , la cantidad de parametro no cambia, otro punto positivo.\n",
        " \n",
        " 2. El número de salidas que elegimos para la capa densa era 1, pero se puede ver que al usar la capa TimeDistributed se modifico la salida, ya que al tener una densa por cada salida de la LSTM, ahora la red tiene 5 salida en vez de una.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vQjnCfgQee1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac1ae9ab-740e-4022-8ca0-6a5cab0d2222"
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0006119798053987324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KQ24YKWedlSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3c4c4293-3ec7-48e6-af49-569b6c05a32c"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ppR_bqyU_lmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusiones finales\n",
        "\n",
        "Saquemos conclusiones ahora que vimos todos los ejemplos:\n",
        "\n",
        "* En este último ejemplo tenemos la misma dimensionalidad que el primer, pero a su favor, permite manejar las secuencias de una forma mas natural que el pimer caso, donde tenemos que entrenar la red pasando cada valor de la secuencia por separado.\n",
        "\n",
        "* Por otro lado se simplifica la red. El ejemplo many-one  tiene la misma dimensionalidad de entrada y salida que este ultimo ejemplo, pero la diferencia importante es que bajamos el numero de parametros a entrenar. Esto se traduce en menor uso de recursos y menor tiempo de entrenamiento."
      ]
    }
  ]
}