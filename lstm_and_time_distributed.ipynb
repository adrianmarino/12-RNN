{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "examples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianmarino/12-RNN/blob/master/lstm_and_time_distributed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DxliPix7Iyr4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando TimeDistributed con LSTM's"
      ]
    },
    {
      "metadata": {
        "id": "EZhlHZXTvhW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One to One"
      ]
    },
    {
      "metadata": {
        "id": "m-jtitj0FWLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2M4jFblFWLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvkTp12bhqli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funciones axiliares\n",
        "\n",
        "Estas son funiones para no mostrar código repetido en los ejemplos. Recomiendo analizarlas cuando lleguemos al momento de utilizarlas, ante no por que es tratar de entender las cosas al revéz.\n"
      ]
    },
    {
      "metadata": {
        "id": "-59ZTMAFGmF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show(model): \n",
        "  model.summary()\n",
        "  dot_mode = model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg')\n",
        "  display(SVG(dot_mode))\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    input_shape, \n",
        "    hidden_neurons, \n",
        "    output_neurons,\n",
        "    use_time_distributed=False\n",
        "):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(\n",
        "      hidden_neurons, \n",
        "      input_shape=input_shape, \n",
        "      return_sequences=use_time_distributed\n",
        "  ))\n",
        "  \n",
        "  output = Dense(output_neurons)\n",
        "  if use_time_distributed:\n",
        "    output = TimeDistributed(output)    \n",
        "  \n",
        "  model.add(output)\n",
        "  \n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  show(model)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(model, X, y, epochs, batch_size):\n",
        "  history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "  loss = history.history['loss'][-1]\n",
        "  print(f'Loss: {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI56g27eFWLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Prepare samples (input/output data)"
      ]
    },
    {
      "metadata": {
        "id": "8nR1GABiFWLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero generamos una array de 5 valores:"
      ]
    },
    {
      "metadata": {
        "id": "3NayPah_FWLq",
        "colab_type": "code",
        "outputId": "2f24ca1a-9f02-4da9-ab1a-179ec898e1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = 5\n",
        "sequence = array([index/float(length) for index in range(length)])\n",
        "print(f'Seq: {sequence}')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq: [0.  0.2 0.4 0.6 0.8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGbIoYBZFWLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, como es un toy example la red va a hacer un echo(Eco), si entra un cero sale un cero y asi sucesivamente. Pero como vamos a entranar una RNN necesitamos que cada ejemplo de input tenga el formato **(N, T, D)**. \n",
        "\n",
        "**LSTM**: Es un RNN con mas memoria que una SimpleRNN, es decir, recuerda secuencias mucho mas largas. \n",
        "\n",
        "¿Pero que es esto?\n",
        "* N: Número de ejemplos presentados a la red.\n",
        "* T: Es la secuencia de datos que se van a pasar por cada ejemplo N.\n",
        "* D: Es la dimesionalidad de cada elemento en la secuencia. Por ejemplo: En este caso estamos pasando números. Un número se puede representar con un solo valor D=1, pero hay casos muy comunes donde la representación puede cambiar, por ejemplo con palabras.\n",
        "\n",
        "* En este caso tenemos 5 ejemplos: [ 0, 0.2, 0.4, 0.6, 0.8] => N=5.\n",
        "* En general con RNN uno quiere predecir el siguiente valor de una secuencia. Por ejemplo, tengo los ultimos 3(T=3) valores [ 0, 0.2, 0.4] y quiero predecir el siguente(0.6). En nuestro caso la secuencia es T=1 por que solo queremos hacer un eco, por eso no tiene sentido usar RNN, con una densa seria lo mismo.\n",
        "* Cada valor de la secuencia se puede representar con una unica dimensión, ya que es un numero. Entonces D=1\n",
        "\n",
        "Input Shape: **(N, T, D)** = (5, 1, 1)\n",
        "\n",
        "¿Y en la salida que le ponemos?\n",
        "\n",
        "la forma de la salida seria (N, D) ya que a la red se le presentan N=5 ejemplos los cuales tiene una dimensión de 1 valor numerico.\n",
        "\n",
        "Output Shape: **(N, D)** = (5, 1)"
      ]
    },
    {
      "metadata": {
        "id": "8hlb457_FWLw",
        "colab_type": "code",
        "outputId": "8743091f-4153-42ff-9bf4-e8d500178b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(len(sequence), 1, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(len(sequence), 1)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (5, 1, 1): [[[0. ]]\n",
            "\n",
            " [[0.2]]\n",
            "\n",
            " [[0.4]]\n",
            "\n",
            " [[0.6]]\n",
            "\n",
            " [[0.8]]]\n",
            "y (5, 1): [[0. ]\n",
            " [0.2]\n",
            " [0.4]\n",
            " [0.6]\n",
            " [0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rbrdeTaPFWL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define LSTM configuration"
      ]
    },
    {
      "metadata": {
        "id": "3t2il7BdFWL1",
        "colab_type": "code",
        "outputId": "e3209d06-2cd5-4ae7-943c-c837302b9bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "input_shape=(1,1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "\n",
        "hidden_neurons = 3\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = length\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 1000\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (1, 1)\n",
            "hidden_neurons: 3\n",
            "output_neurons: 1\n",
            "batch_size: 5\n",
            "epochs: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-C-Su3gdwEeu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora analicemos mejorlos parametros:\n",
        "\n",
        "####  ¿Porque 5 neuronas ocultas?\n",
        "\n",
        "En realidad este numero no tiene ninguna relacion con el N=5. no la busquen por que no la hay!. El numero de neuronas ocultas es arbitrario, se elige lo que mejor funciona pero: \n",
        "\n",
        "¿Hay alguna forma de elegir elmenor numero de neuronas que minimize el numero de parametros de la red?\n",
        "\n",
        "Al parecer hay una forma de calcularlo pero es una aplroximación, una guia:\n",
        "\n",
        ">$ 𝑁ℎ=𝑁𝑠 / (𝛼∗(𝑁𝑖+𝑁𝑜))$\n",
        "\n",
        "Donde:\n",
        "* $𝑁h$ = El lo que queremos averiguar, el número de neuronas de oa capa oculata de la LSTM. \n",
        "* $𝑁i$ = El número de neuronas de entrada (Que seria el tamaño de la secuencia T)\n",
        "* $𝑁𝑜$ = El número de neuronas de salida (La dimencionalidad?).\n",
        "* $𝑁𝑠$ = El número de ejemplos de entrenamiento(En nuestro ejemplo es N=5). \n",
        "* $𝛼$ = Es un factor de escala arbitrario entre 2 y 10.\n",
        "\n",
        "Pero mas alla de esta explicación: ** No hay reglas claras para elegir el numero de neuronas acoltas, es algo que se descubre con prueba y error y depeden del problema a resolver.**\n",
        "\n",
        "[Ver Referencia](https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm)\n",
        "\n",
        "####  ¿Por que batch_size=5?\n",
        "\n",
        "Sabemos que una RNN  decide su salida actual en base al input actual y tambien a los inputs anteriores. Esto quiere decir que la red garda estado. Ahora bien, al momento de entranar la red sabemos que el estado no se conserva entre batches. si el batch size fuese 1 no tendria serntido usar una RNN ya que no importaria el orden en que se le muestran los ejemplos y nuevamente seria lo mismo que usar una red Densa.\n",
        "\n",
        "####  ¿Por que una reurona de salida?\n",
        "\n",
        "Como hablamos, que ingrear cada valor por separado y tener un valor de salida por eso tenemos una nerona de salida. Cada salida representa un valor.\n",
        "\n",
        "####  ¿Por que input_shape=(1,1)?\n",
        "\n",
        "input_shapr es la forma que tienecada ejemplo en la entrada de la capa. En caso cada ejemplo\n",
        "tiene una secuencia de 1 valor y cada valor tiene una dimensionalidad de 1.\n",
        "\n",
        "input_shape=**(T, D)**\n",
        "\n",
        "\n",
        "####  ¿Por que epochs=1000?\n",
        "Esto tambien es arbitrario, pero la regla es elegir el menor numero de epochs para el cual se llegue al resultado esperado. \n",
        "Es decir, en este caso con 1000 epochs el resultado es el esperado. Si elegimos 10.000 estamos mejorando el error pero es necesario? El resutlado no seria el mismo?"
      ]
    },
    {
      "metadata": {
        "id": "ei3BnQxKFWL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create LSTM"
      ]
    },
    {
      "metadata": {
        "id": "NTBKQA6zFWL6",
        "colab_type": "code",
        "outputId": "d744a9e5-3cd4-41e5-83ad-ac901f239cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_17 (LSTM)               (None, 3)                 60        \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139687690419112 -->\n<g class=\"node\" id=\"node1\">\n<title>139687690419112</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_17: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 1, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 3)</text>\n</g>\n<!-- 139687689078432 -->\n<g class=\"node\" id=\"node2\">\n<title>139687689078432</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_14: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 3)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139687690419112&#45;&gt;139687689078432 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139687690419112-&gt;139687689078432</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139687691843008 -->\n<g class=\"node\" id=\"node3\">\n<title>139687691843008</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">139687691843008</text>\n</g>\n<!-- 139687691843008&#45;&gt;139687690419112 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139687691843008-&gt;139687690419112</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FxeJhdjCFWL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train LSTM"
      ]
    },
    {
      "metadata": {
        "id": "6nWu306BFWMA",
        "colab_type": "code",
        "outputId": "41d21a21-898b-440a-e559-729cf49126e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.00012466800399124622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Dz1EE6AFWME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "_zOaRVVeFWMF",
        "colab_type": "code",
        "outputId": "569087a2-eecf-440e-d642-86c6f039b01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X]\n",
        "outputs = [\"%.1f\" % output for output in predictions]\n",
        "\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSl2ErvHvtiJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many to One\n",
        "\n",
        "La idea en este caso es tomar como entradas toda la seguencia y en la salida tener toda la secuencia, todo en un solo paso a diferencia del caso anterior."
      ]
    },
    {
      "metadata": {
        "id": "OEQoNwdDZNwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dimensionalidad de entrada\n",
        "\n",
        "* N=1: Entonces si pasamos la secuencia completa en un solo paso, vamos a tener un solo ejemplo.\n",
        "* T=5: Este unico ejemplo tiene una secuencia (temporal) de tamaño 5.\n",
        "* D=1: La dimencionalidad del cada elemento de la secuenca no cambia, por que seguimos trabajando con numeros que se pueden representar en un solo valor ,como hablamos anteriormente.\n",
        "\n",
        "=> **(N, T, D)** = (1, 5, 1)\n",
        "\n",
        "### Dimensionalidad de salida\n",
        "\n",
        "=> **(N, T)** = (1, 5)\n",
        "\n",
        "* N=1: Solo hay un ejemplo, por o tanto habra un solo resultados a la salida.\n",
        "*T=5. Cada elemento de salida tiene 5 valores, uno por cada elemento en la secuencia de entrada.\n",
        "\n",
        "\n",
        "Una cosa a tener en cuenta es que N es *variable**! Es la cantidad de ejemplos que le pasamos a la red para entrenar. Osea, podriamos pasar mas o menos ejemplos. \n",
        "Por esta cuestion cuando hacemos model.summary() N aparece como **None**.Se refiere a que dimensión no esta definida. Osea, la red no tiene una restricción en el número de ejemplos a pasar. N es 1 para este ejemplo, por que no tenemos mas datos."
      ]
    },
    {
      "metadata": {
        "id": "S2KrIEj2ZMGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6b6db130-e982-4860-ebbe-dd39f1ca89d6"
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5): [[0.  0.2 0.4 0.6 0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXBaN4spgBvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9187bf17-865c-47de-d0e9-eb24f0605e0b"
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 3\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 5\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 500\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 3\n",
            "output_neurons: 5\n",
            "batch_size: 1\n",
            "epochs: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZaOf4xqGkzwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buen aca cambiaron alguna cosas:\n",
        "\n",
        "#### ¿Porque input_shape=(5, 1)?\n",
        " \n",
        "En este caso cada ejemplo tiene una secuenca de 5 valores y cada valor una dimensión 1.\n",
        "\n",
        "#### ¿Por que 3 neuronas ocultas?\n",
        "\n",
        "Como ya aclaramos en el caso anterior, este numero es arbrario, se elije lo que mejor fucione, pero buscando el número mas bajo con el cual se tenga buenos resultados.\n",
        "\n",
        "#### ¿Por que 5 neuronas de salida?\n",
        "\n",
        "Bueno, la idea es ingresar un ejemplo con una secuencia de 5 valores y a la salida tener un eco de estos mismo 5 valores, asi que necesitamos 5 salidas.\n",
        "\n",
        "####  ¿Por que batch_size=1?\n",
        "\n",
        "Bueno acá hay un **tema importante a aclarar**. No nos olvidemos que estamos trabajando con redas neuronales recurrentes. Como sabemos, estas infieren la salida por que recuerdan entradas anteriores, ya que poseen una memoria que puede ser mayor o menor, dependiendo de la implementación que usemos (LSTM, SimpleRNN, GRU, etc...).\n",
        "\n",
        "Ahora bien, para tener memoria, la red tiene un estado. Al momento de entranar la red podemos elegir cuando resetear este estado interno. Por defecto, Keras resetea el estado al comenzar cada batch de ejemplos. Si por alguna razón queremos modificar este comportamiento podemos utilizar el atributo statefull de keras.\n",
        "\n",
        "* stateful = True :  En este caso al finalizar el entrenamiento del último ejemplo de un batch de entrenamiento se toma ese estado y se lo pone a la entrada antes de procesar el primer ejemplo del siguiente batch. Es decir, lo que hace es conservar el estado de la red entre batches. Luego una puede resetear ese estado en el momento que se quiera. \n",
        "\n",
        "\n",
        "* stateful = False: Es el valor por defecto y en este caso no se conserva el estado entre batches. \n",
        "\n",
        "Si razonamos un poco, podemos entender que el batch_size seria el número de ejemplo que\n",
        "queremos que la red recuede si statefull=False. Si statefull=True, esto se modifica dependeiendo que cuando hagamos el reset de la red. Pero se entiende que seria una forma de modificar el número de ejemplos que que pue memorizar la red. Ahora bien, esto me parece que no hay que tomarlo en sentido estricto ya que no sabemos cuando recuerda la red, creo que es algo que depende del problema a resolver.\n",
        "\n",
        "Por esta cuestión el batch_size elegido es 1. Ya que no hace falta guardar el estado mas alla de los 5 valores.\n",
        "\n",
        "[Ver Referencia](http://philipperemy.github.io/keras-stateful-lstm/)\n",
        "\n",
        "####  ¿Por que epochs=500?\n",
        "\n",
        "Bueno en este caso como se le pasa toda la secuencia a la red necesitamenos iteraciones para llegar al resultado esperado."
      ]
    },
    {
      "metadata": {
        "id": "uTzY13KIflfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ba46a40f-ab67-454e-cb90-9297941c77be"
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_18 (LSTM)               (None, 3)                 60        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 20        \n",
            "=================================================================\n",
            "Total params: 80\n",
            "Trainable params: 80\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 263.00 211.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 259,-207 259,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139687677844056 -->\n<g class=\"node\" id=\"node1\">\n<title>139687677844056</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 255,-129.5 255,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-102.8\">lstm_18: LSTM</text>\n<polyline fill=\"none\" points=\"110,-83.5 110,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"110,-106.5 168,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"168,-83.5 168,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"168,-106.5 255,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">(None, 3)</text>\n</g>\n<!-- 139687693741808 -->\n<g class=\"node\" id=\"node2\">\n<title>139687693741808</title>\n<polygon fill=\"none\" points=\"5.5,-.5 5.5,-46.5 249.5,-46.5 249.5,-.5 5.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_15: Dense</text>\n<polyline fill=\"none\" points=\"119.5,-.5 119.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"119.5,-23.5 177.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"177.5,-.5 177.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-31.3\">(None, 3)</text>\n<polyline fill=\"none\" points=\"177.5,-23.5 249.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 139687677844056&#45;&gt;139687693741808 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139687677844056-&gt;139687693741808</title>\n<path d=\"M127.5,-83.3799C127.5,-75.1745 127.5,-65.7679 127.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-56.784 127.5,-46.784 124.0001,-56.784 131.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139687693741864 -->\n<g class=\"node\" id=\"node3\">\n<title>139687693741864</title>\n<polygon fill=\"none\" points=\"63,-166.5 63,-202.5 192,-202.5 192,-166.5 63,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-180.8\">139687693741864</text>\n</g>\n<!-- 139687693741864&#45;&gt;139687677844056 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139687693741864-&gt;139687677844056</title>\n<path d=\"M127.5,-166.4092C127.5,-158.4308 127.5,-148.795 127.5,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"131.0001,-139.5333 127.5,-129.5333 124.0001,-139.5334 131.0001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TadUYYubxGuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0df5fda-70c0-48e1-eb31-5e6197285980"
      },
      "cell_type": "code",
      "source": [
        "train(model, X, y, epochs, batch_size)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.943455701398534e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtGcPhlLyFaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8add1c68-520b-4059-9e67-15bd05ba9e37"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "inputs = [\"%.1f\" % x for x in X[0]]\n",
        "outputs = [\"%.1f\" % y for y in predictions[0]]\n",
        "print(f'Inputs: {inputs}\\nOutputs: {outputs}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n",
            "Outputs: ['0.0', '0.2', '0.4', '0.6', '0.8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnVqsPT6z628",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Conclusiones hasta el momento\n",
        "\n",
        "Hasta acá, podemos ver la cantidad de parametros de la LSMT no cambio. Osea, que si cambio el tamaño de la secuencia en una LSTM no cambia el número de sus hiperparametros, lo cual es un punto positivo. \n",
        "\n",
        "Por otro lado, podemos ver que la capa densa de salida si cambio. Ahora tenemos mas parametros a entrenar: 29 pesos + un bias.\n",
        "\n",
        "Otro tema a tener en cuenta, es que podriamos haber usado una cadadensa es vez de una LSTM, ya que en este ejemplo no estamos usando la memoria que tiene la LSTM entre ejemplos. con una densa de 5 entradas era suficiente.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZDIEb9FZ2HfV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Many-to-Many con wrapper TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "Hj3JvKWx2Gb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fa3c93ee-8818-4c31-f7b4-3e4af8582164"
      },
      "cell_type": "code",
      "source": [
        "X = sequence.reshape(1, 5, 1)\n",
        "print(f'X {X.shape}: {X}')\n",
        "\n",
        "y = sequence.reshape(1, 5)\n",
        "print(f'y {y.shape}: {y}')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1, 5, 1): [[[0. ]\n",
            "  [0.2]\n",
            "  [0.4]\n",
            "  [0.6]\n",
            "  [0.8]]]\n",
            "y (1, 5): [[0.  0.2 0.4 0.6 0.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rn5OCbBt2YVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "842fb792-abb5-4cf0-eddd-b4a515c2600c"
      },
      "cell_type": "code",
      "source": [
        "input_shape=(5, 1)\n",
        "print(f'input_shape: {input_shape}')\n",
        "\n",
        "hidden_neurons = 3\n",
        "print(f'hidden_neurons: {hidden_neurons}')\n",
        "\n",
        "output_neurons = 1\n",
        "print(f'output_neurons: {output_neurons}')\n",
        "\n",
        "batch_size = 1\n",
        "print(f'batch_size: {batch_size}')\n",
        "\n",
        "epochs = 100\n",
        "print(f'epochs: {epochs}')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 1)\n",
            "hidden_neurons: 3\n",
            "output_neurons: 1\n",
            "batch_size: 1\n",
            "epochs: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJWnMtWb3qUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "473d2c97-9fe2-4719-a152-ce8f931bdd31"
      },
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, hidden_neurons, output_neurons, use_time_distributed=True)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_26 (LSTM)               (None, 5, 3)              60        \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 5, 1)              4         \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"211pt\" viewBox=\"0.00 0.00 486.00 211.00\" width=\"486pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-207 482,-207 482,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139687648787480 -->\n<g class=\"node\" id=\"node1\">\n<title>139687648787480</title>\n<polygon fill=\"none\" points=\"111.5,-83.5 111.5,-129.5 366.5,-129.5 366.5,-83.5 111.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-102.8\">lstm_26: LSTM</text>\n<polyline fill=\"none\" points=\"221.5,-83.5 221.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"221.5,-106.5 279.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"279.5,-83.5 279.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-114.3\">(None, 5, 1)</text>\n<polyline fill=\"none\" points=\"279.5,-106.5 366.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-91.3\">(None, 5, 3)</text>\n</g>\n<!-- 139687646814672 -->\n<g class=\"node\" id=\"node2\">\n<title>139687646814672</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 478,-46.5 478,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-19.8\">time_distributed_9(dense_19): TimeDistributed(Dense)</text>\n<polyline fill=\"none\" points=\"333,-.5 333,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"333,-23.5 391,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"391,-.5 391,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-31.3\">(None, 5, 3)</text>\n<polyline fill=\"none\" points=\"391,-23.5 478,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-8.3\">(None, 5, 1)</text>\n</g>\n<!-- 139687648787480&#45;&gt;139687646814672 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139687648787480-&gt;139687646814672</title>\n<path d=\"M239,-83.3799C239,-75.1745 239,-65.7679 239,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-56.784 239,-46.784 235.5001,-56.784 242.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139687648787872 -->\n<g class=\"node\" id=\"node3\">\n<title>139687648787872</title>\n<polygon fill=\"none\" points=\"174.5,-166.5 174.5,-202.5 303.5,-202.5 303.5,-166.5 174.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-180.8\">139687648787872</text>\n</g>\n<!-- 139687648787872&#45;&gt;139687648787480 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139687648787872-&gt;139687648787480</title>\n<path d=\"M239,-166.4092C239,-158.4308 239,-148.795 239,-139.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"242.5001,-139.5333 239,-129.5333 235.5001,-139.5334 242.5001,-139.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "duRHbLHY62NL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bueno aca hay varias cosas nuevas:\n",
        "\n",
        "1. use_time_distributed=True: Este parametro esta haciendo dos cosas muy importante al momento de construir el modelo:\n",
        "  * Primero configura la capa LSTM para que retorne todas las salidad de la red(return_sequences=True) . Recordemos que un LSTM tiene una salida por cada elemento de la secuencia de entreada. Si tenemos una secuencia de 5, tenemos 5 steps en la red y cada uno tiene una salida. En este caso entonces la LSTM tiene 5 entradas y 5 salidas. Luego, cada salida tiene la dimensión igual al número de neuronas ocultas, que en este caso es 3. Cabe destacar que  con return_sequences=False se toma la salida del step 5 (último) de la LSTM.\n",
        "  * Segundo, se agrego una capa que envuelve(wrapea) la capa densa de salida. Lo que hace esta capa, es repetirla la capa densa por cada salida de la LSTM, pero con la condición de que los pesos de la densa se compartan entre todas las salida. Es decir que si la secuencia de 100 en vez de 5 , la cantidad de parametro no cambia, otro punto positivo.\n",
        " \n",
        " 2. El número de salidas que elegimos para la capa densa era 1, pero se puede ver que al usar la capa TimeDistributed se modifico la salida, ya que al tener una densa por cada salida de la LSTM, ahora la red tiene 5 salida en vez de una.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ppR_bqyU_lmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusiones finales\n",
        "\n",
        "Saquemos conclusiones ahora que vimos todos los ejemplos:\n",
        "\n",
        "* En este último ejemplo tenemos la misma dimensionalidad que el primer, pero a su favor, permite manejar las secuencias de una forma mas natural que el pimer caso, donde tenemos que entrenar la red pasando cada valor de la secuencia por separado.\n",
        "\n",
        "* Por otro lado se simplifica la red. El ejemplo many-one  tiene la misma dimensionalidad de entrada y salida que este ultimo ejemplo, pero la diferencia importante es que bajamos el numero de parametros a entrenar. Esto se traduce en menor uso de recursos y menor tiempo de entrenamiento."
      ]
    }
  ]
}