{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Bidireccional\n",
    "\n",
    "¿Por qué RNN bidireccional?\n",
    "\n",
    "Tareas de NLP -> Entidades: Nombres, fechas, lugares, etc.\n",
    "Para la detección de estas entidades, es mejor tener información de toda la secuencia de principio a fin, y no solamente hasta un t particular.\n",
    "\n",
    "\"**General** relativity is an exciting theory about the physics of space and time\".\n",
    "\n",
    "En esta oración \"General\" no es una entidad.\n",
    "\n",
    "\"**General** Zod is an enemy of Superman\"\n",
    "En esta oración \"General\" es una persona\n",
    "\n",
    "Esta decisión no se puede tomar si no miro toda la oración.\n",
    "Para este tipo de problemas se utilizan RNN Bidireccionales:\n",
    "\n",
    "<img src=\"bidir-rnn.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Tiene sentido seguir viendo solamente el último estado?\n",
    "\n",
    "No, porque la backward RNN no procesó la secuencia. Tiene sentido definir:\n",
    "\n",
    "$$ out = [h^f_T, h^b_1] $$\n",
    "\n",
    "En el caso que uno quiera implementar many to one.\n",
    "\n",
    "Este es el comportamiento de bidirectional en Keras, si return_sequences=False\n",
    "\n",
    "Para implementarlo en Keras se hace muy fácilmente:\n",
    "\n",
    "LSTM(M) -> Bidirectional(LSTM(M))\n",
    "\n",
    "* ¿Cuándo no usar RNN bidireccionales?\n",
    "\n",
    "Cuando se hace predicción, ya que no tengo datos para $t > t_0$\n",
    "\n",
    "## ¿Cómo afecta return_states y return_sequences en una Bidirectional RNN?\n",
    "\n",
    "Implementemos un código de prueba para analizar el comportamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'bidirectional_1/concat:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'bidirectional_1/while/Exit_3:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while/Exit_4:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_3:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_4:0' shape=(?, 3) dtype=float32>]\n",
      "o: [[-0.26224297 -0.03154224  0.18159726 -0.10032201 -0.20889407 -0.00458867]]\n",
      "o.shape: (1, 6)\n",
      "h1: [[-0.26224297 -0.03154224  0.18159726]]\n",
      "c1: [[-0.5859647  -0.07311182  0.41462934]]\n",
      "h2: [[-0.10032201 -0.20889407 -0.00458867]]\n",
      "c2: [[-0.15180665 -0.9164332  -0.014694  ]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Bidirectional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T = 8 #Cantidad de Timesteps\n",
    "D = 2 #Cantidad de entradas por timestep\n",
    "M = 3 #Cantidad de unidades en la capa oculta\n",
    "\n",
    "\n",
    "X = np.random.randn(1, T, D)\n",
    "\n",
    "\n",
    "input_ = Input(shape=(T, D))\n",
    "#rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=True),merge_mode=\"concat\")\n",
    "rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=False),merge_mode=\"concat\") \n",
    "# merge_mode, defalut=\"concat\"... también {'sum','ave','mul'}\n",
    "x = rnn(input_)\n",
    "print(x)\n",
    "model = Model(inputs=input_, outputs=x)\n",
    "o, h1, c1, h2, c2 = model.predict(X)\n",
    "print(\"o:\", o)\n",
    "print(\"o.shape:\", o.shape)\n",
    "print(\"h1:\", h1)\n",
    "print(\"c1:\", c1)\n",
    "print(\"h2:\", h2)\n",
    "print(\"c2:\", c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Función que devuelve datos formateados\n",
    "def get_data(data_path = 'fra-eng/fra.txt', num_samples = 10000):\n",
    "    # num_samples: Number of samples to train on.\n",
    "    # Vectorize the data.\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    input_characters = set()\n",
    "    target_characters = set()\n",
    "    lines = open(data_path).read().split('\\n')\n",
    "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "        input_text, target_text = line.split('\\t')\n",
    "        # We use \"tab\" as the \"start sequence\" character\n",
    "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "        target_text = '\\t' + target_text + '\\n'\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        for char in input_text:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "    input_characters = sorted(list(input_characters))\n",
    "    target_characters = sorted(list(target_characters))\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "    input_lenghts = [len(txt) for txt in input_texts]\n",
    "    output_lengths = [len(txt) for txt in target_texts]\n",
    "    max_encoder_seq_length = max(input_lenghts)\n",
    "    max_decoder_seq_length = max(output_lengths)\n",
    "    print('Traducción con secuencia mas larga (Notar el agregado de tab y enter):')\n",
    "    print(input_texts[np.argmax(output_lengths)])\n",
    "    print(target_texts[np.argmax(output_lengths)])\n",
    "\n",
    "    print('Number of samples:', len(input_texts))\n",
    "    print('Number of unique input tokens:', num_encoder_tokens)\n",
    "    print('Number of unique output tokens:', num_decoder_tokens)\n",
    "    print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "    print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "    input_token_index = dict(\n",
    "        [(char, i) for i, char in enumerate(input_characters)])\n",
    "    target_token_index = dict(\n",
    "        [(char, i) for i, char in enumerate(target_characters)])\n",
    "    encoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "        dtype='float32')\n",
    "    decoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "            input_token_index, target_token_index, \\\n",
    "            num_encoder_tokens, num_decoder_tokens, \\\n",
    "            max_encoder_seq_length, max_decoder_seq_length, \\\n",
    "            input_texts, target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traducción con secuencia mas larga (Notar el agregado de tab y enter):\n",
      "I figured I might be able to help.\n",
      "\tJe me suis imaginée que je pourrais être en mesure de donner un coup de main.\n",
      "\n",
      "Number of samples: 100000\n",
      "Number of unique input tokens: 80\n",
      "Number of unique output tokens: 110\n",
      "Max sequence length for inputs: 34\n",
      "Max sequence length for outputs: 79\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "input_token_index, target_token_index, \\\n",
    "num_encoder_tokens, num_decoder_tokens,  \\\n",
    "max_encoder_seq_length, \\\n",
    "max_decoder_seq_length, \\\n",
    "input_texts, target_texts = get_data(num_samples = num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioma Ingles:\n",
      "Entrada encoder: (100000, 34, 80)\n",
      "Idioma frances:\n",
      "Entrada decoder: (100000, 79, 110)\n",
      "Salida decoder: (100000, 79, 110)\n"
     ]
    }
   ],
   "source": [
    "print('Idioma Ingles:')\n",
    "print('Entrada encoder:', encoder_input_data.shape)\n",
    "print('Idioma frances:')\n",
    "print('Entrada decoder:', decoder_input_data.shape)\n",
    "print('Salida decoder:', decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None, 80)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 256), (None, 214016      Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Dencoder_Inputs (InputLayer)    (None, None, 110)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 256),  375808      Dencoder_Inputs[0][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Model_Output (Dense)            (None, None, 110)    28270       Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 618,094\n",
      "Trainable params: 618,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, concatenate, Bidirectional\n",
    "# Estamos utilizando la Functional API\n",
    "\n",
    "# Esto es donde guardará el contexto\n",
    "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name=\"Encoder_Inputs\") #num_encoder_tokens es la cantidad de features a la entrada\n",
    "encoder = Bidirectional(LSTM(latent_dim, return_state=True, name=\"Encoder_LSTM\"))\n",
    "encoder_outputs = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [concatenate([encoder_outputs[1], encoder_outputs[3]]),concatenate([encoder_outputs[2], encoder_outputs[4]])]\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name=\"Dencoder_Inputs\") #num_decoder_tokens es la cantidad de features a la entrada del decoder\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(2*latent_dim, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Model_Output')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 47s 585us/step - loss: 0.9389 - val_loss: 1.0251\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 40s 495us/step - loss: 0.6722 - val_loss: 0.8853\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 42s 527us/step - loss: 0.5932 - val_loss: 0.8129\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 41s 510us/step - loss: 0.5460 - val_loss: 0.7624\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 41s 513us/step - loss: 0.5121 - val_loss: 0.7229\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 40s 501us/step - loss: 0.4854 - val_loss: 0.6921\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 40s 502us/step - loss: 0.4628 - val_loss: 0.6665\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 40s 497us/step - loss: 0.4438 - val_loss: 0.6450\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 41s 508us/step - loss: 0.4274 - val_loss: 0.6240\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 42s 529us/step - loss: 0.4127 - val_loss: 0.6056\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 41s 515us/step - loss: 0.3999 - val_loss: 0.5911\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 41s 512us/step - loss: 0.3887 - val_loss: 0.5783\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 41s 518us/step - loss: 0.3784 - val_loss: 0.5663\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 43s 539us/step - loss: 0.3690 - val_loss: 0.5551\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 42s 521us/step - loss: 0.3605 - val_loss: 0.5468\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 42s 529us/step - loss: 0.3526 - val_loss: 0.5368\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 39s 489us/step - loss: 0.3456 - val_loss: 0.5291\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 40s 495us/step - loss: 0.3387 - val_loss: 0.5223\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 40s 501us/step - loss: 0.3324 - val_loss: 0.5162\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 42s 523us/step - loss: 0.3266 - val_loss: 0.5098\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 41s 512us/step - loss: 0.3211 - val_loss: 0.5027\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 44s 545us/step - loss: 0.3157 - val_loss: 0.4980\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 42s 528us/step - loss: 0.3111 - val_loss: 0.4939\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 40s 500us/step - loss: 0.3062 - val_loss: 0.4910\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 41s 510us/step - loss: 0.3016 - val_loss: 0.4847\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 41s 515us/step - loss: 0.2978 - val_loss: 0.4812\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 41s 510us/step - loss: 0.2936 - val_loss: 0.4798\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 41s 509us/step - loss: 0.2899 - val_loss: 0.4758\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 41s 513us/step - loss: 0.2864 - val_loss: 0.4717\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 41s 515us/step - loss: 0.2828 - val_loss: 0.4691\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 41s 516us/step - loss: 0.2796 - val_loss: 0.4680\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 41s 513us/step - loss: 0.2764 - val_loss: 0.4651\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 41s 518us/step - loss: 0.2732 - val_loss: 0.4620\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 41s 517us/step - loss: 0.2705 - val_loss: 0.4585\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 41s 517us/step - loss: 0.2676 - val_loss: 0.4595\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 41s 518us/step - loss: 0.2648 - val_loss: 0.4530\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 42s 527us/step - loss: 0.2622 - val_loss: 0.4546\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 46s 576us/step - loss: 0.2597 - val_loss: 0.4509\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 45s 560us/step - loss: 0.2574 - val_loss: 0.4521\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 44s 556us/step - loss: 0.2550 - val_loss: 0.4484\n",
      "Epoch 41/100\n",
      "19968/80000 [======>.......................] - ETA: 30s - loss: 0.2521"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "batch_size = 256  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(2*latent_dim,), name=\"State_input_h\")\n",
    "decoder_state_input_c = Input(shape=(2*latent_dim,), name=\"State_input_c\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts2, target_texts2 = get_data(num_samples = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(8000,8100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
