{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Networks)\n",
    "Articulos recomendado: \n",
    "- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- http://blog.echen.me/2017/05/30/exploring-lstms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que tienen de nuevo respecto a MLP y CNN?\n",
    "- MLP y CNN solo aceptan un vector de entrada de tamaño fijo y devuelve un vector de salida de tamaño fijo\n",
    "- RNN trabjan con secuencias tanto a la entrada como a la salida\n",
    "- No tienen por que estrictamente tener una secuencia ni a la entrada ni a la salidad. De hecho hasta podrían no tener nada a la \"entrada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_types.jpeg](rnn_types.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aclaraciones: \n",
    "- Cada cuadrado NO es una neurona si no una capa que puede contener N neuronas\n",
    "- Cada flecha representa la interconexión entre dos capas. Los pesos forman una matriz de la N1xN2 donde N1 y N2 son la cantidad de neuronas en cada capa respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos\n",
    "- **One to One**: CNN, MLP\n",
    "- **One to many**: [Image captioning](https://www.youtube.com/watch?v=xKt21ucdBY0)\n",
    "- **Many to one**: Sentiment Analisys, Detectar voz de hombre vs voz de mujer\n",
    "- **Many to Many** [(sequence to sequence)](https://youtu.be/dkHdEAJnV_w): [Traducción](https://github.com/jganzabal/aind2-nlp-capstone/blob/master/machine_translation.ipynb) Dimensión de entrada differente a la de salida.\n",
    "- **Many to Many Sincronizado**: Etiquetado de tramas de video, POS (Part of Speech) cada palabra se clasifica en verbo, articulo, etc, speech2text, text2speech, NER (Named Entity Recognition). Dimensión de entrada igual a dimensión de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de lenguaje Generativos:\n",
    "- Predecir la proxima palabra en funcion de las anteriores\n",
    "- Predecir el proximo caracter en función de los anteriores\n",
    "\n",
    "**Resultado**: Probabilidad dada la secuencia de caracteres o de palabras\n",
    "\n",
    "**Aplicaciones de los modelos de lenguaje** (Mas allá de la posibilidad de generar texto):\n",
    "- OCR\n",
    "- Speach2Text\n",
    "- Detección de autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.\"\n",
    "- Es una secuencia de ejecución mas que una clasificación\n",
    "- Las RNN son Turing completo en principio [Turing Complete](https://en.wikipedia.org/wiki/Turing_completeness), [RNN Turing complete](http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalles de la arquitectura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidad de Elman o RNN unit\n",
    "\n",
    "**Nota importante**: Cada unidad no es una neurona sino que una capa\n",
    "\n",
    "![RNN_vs_FNN.png](RNN_vs_FNN.png)\n",
    "\n",
    "¿Cual es el tamaño de $W_h$?\n",
    "\n",
    "Todo se conecta con todo -> Si hay M hidden units tenemos $M^2$ $W_h$s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En ecuaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN\n",
    "\n",
    "$h_t = f(W_x^T X_t + b_h)$\n",
    "\n",
    "$y_t = softmax(W_o^T h_t + b_o)$\n",
    "\n",
    "$f$ usualmente RELU, sigmoidea, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t = f(W_h^T h_{t-1} + W_x^T X_t + b_h)$\n",
    "\n",
    "$y_t = softmax(W_o^T h_t + b_o)$\n",
    "\n",
    "$f$ es tanh usualmente pero puede ser RELU, sigmoid, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con dos neuronas en la capa oculta\n",
    "\n",
    "La idea es comprender paso a paso los calculos en cada paso de la red hasta hallar el valor de la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![unfold_RNN.png](unfold_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero calculamos la salida(ht) de la funcion de activacion 'f' que en este caso va a ser una 'tanh':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 2\n",
      "h(t=0):\n",
      "[[ 1]\n",
      " [-2]]\n",
      "Wh:\n",
      "[[ 0 -1]\n",
      " [ 2  1]]\n",
      "X(t=1):\n",
      "[[ 1]\n",
      " [-1]\n",
      " [ 2]]\n",
      "Wx:\n",
      "[[-1  1]\n",
      " [ 1  0]\n",
      " [ 2  1]]\n",
      "bh:\n",
      "[[-1]\n",
      " [ 1]]\n",
      "\n",
      "Cantidad de parametros de recurrente(que la red tiene que aprender/ajustar): 12\n"
     ]
    }
   ],
   "source": [
    "print_matrix = lambda name, matrix: print(f'{name}:\\n{matrix.view()}')\n",
    "\n",
    "# M: Cantidad de neuronas en la capa oculta.\n",
    "M = 2\n",
    "print('M:', M)\n",
    "\n",
    "# h0: Valores iniciales de la capa oculta, vector columna de Mx1.\n",
    "h0 = np.array([1, -2]).reshape(2, 1)\n",
    "print_matrix('h(t=0)', h0)\n",
    "\n",
    "# Wh: Matriz de pesos de capa oculta MxM.\n",
    "Wh = np.array([[0, -1], [2, 1]])\n",
    "print_matrix('Wh', Wh)\n",
    "\n",
    "# Dimension de entrada 3 en este ejemplo.\n",
    "Xt = np.array([1, -1, 2]).reshape(3,1) # Vector columna\n",
    "print_matrix('X(t=1)', Xt)\n",
    "\n",
    "# Dimension de Wx?\n",
    "# Re: Dimensión 3x2 para que Wx.T sea de 2x3\n",
    "Wx = np.array([[-1, 1], [1, 0], [2, 1]])\n",
    "print_matrix('Wx', Wx)\n",
    "\n",
    "\n",
    "# Dimensión Mx1\n",
    "bh = np.array([-1, 1]).reshape(2,1)\n",
    "print_matrix('bh', bh)\n",
    "\n",
    "\n",
    "total_params_r_layer = Wh.shape[0] * Wh.shape[1] + Wx.shape[0] * Wx.shape[1] + bh.shape[0]\n",
    "\n",
    "print('\\nCantidad de parametros de recurrente(que la red tiene que aprender/ajustar):', total_params_r_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [-1,  1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wh.T # T: Roto en direccion agujas y luego mirror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4],\n",
       "       [-3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wh.T.dot(h0) # Producto escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Wx.T.dot(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argumneto de h(t):\n",
      "[[-3]\n",
      " [ 1]]\n",
      "h(t=1):\n",
      "[[-0.99505475]\n",
      " [ 0.76159416]]\n"
     ]
    }
   ],
   "source": [
    "h_arg = Wh.T.dot(h0) + Wx.T.dot(Xt) + bh\n",
    "h1 = np.tanh(h_arg) # Ver grafico tanh!\n",
    "\n",
    "print(f'Argumneto de h(t):\\n{h_arg}')\n",
    "print(f'h(t=1):\\n{h1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1200px-Hyperbolic_Tangent.svg.png](1200px-Hyperbolic_Tangent.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula de la salida de la softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wo:\n",
      "[[0.5 0.4 0.3]\n",
      " [0.5 0.1 0.5]]\n",
      "ao:\n",
      "[[ 0. ]\n",
      " [ 0.3]\n",
      " [-0.5]]\n",
      "Salida:\n",
      " [[0.33825043]\n",
      " [0.45659032]\n",
      " [0.20515925]]\n",
      "\n",
      "Cantidad de parametros de capa densa de salida: 9\n"
     ]
    }
   ],
   "source": [
    "# Salida de 3 neuronas en la capa oculta:\n",
    "\n",
    "Wo = np.array([[0.5, 0.4],[0.3, 0.5],[0.1, 0.5]]).reshape(2,3)\n",
    "bo = np.array([0.5, 0.1, 0.2]).reshape(3,1)\n",
    "ao = Wo.T.dot(h0) + bo\n",
    "\n",
    "print_matrix('Wo', Wo)\n",
    "print_matrix('ao', ao)\n",
    "\n",
    "softmax = lambda x: np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "print('Salida:\\n', softmax(ao))\n",
    "\n",
    "total_params_out_layer = Wo.shape[0] * Wo.shape[1] + bo.shape[0]\n",
    "\n",
    "print('\\nCantidad de parametros de capa densa de salida:', total_params_out_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 2 # M\n",
    "time_steps = 1000 # T\n",
    "n_features = 3 # D\n",
    "input_shape = (time_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons, input_shape = input_shape))\n",
    "model.add(Dense(3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desplegando (Unfolding) la RNN\n",
    "#### BPTT (Back-Propagation Through Time)\n",
    "- Secuencia de longitud 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![unfold_RNN.png](unfold_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- Es como una FNN con 5 hidden layers pero con pesos compartidos (Shared weights): $W_h, W_o, W_x$\n",
    "- Donde habiamos visto pesos compartidos?\n",
    "- Se puede pensar como si h fuera la entrada y X es una señal de control en cada paso\n",
    "\n",
    "Preguntas:\n",
    "- Son todas las Y importantes? En que casos?\n",
    "- Que diferencia hay entre estado interno (internal state) de la RNN y los pesos?\n",
    "- Cada cuanto se resetea el estado interno? Y los pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalles de la entrada $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrada en Vanilla Networks:\n",
    "\n",
    "NxD, donde N es la cantidad de muestras y D es la cantidad de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.3]\n",
      " [0.2 0.1]\n",
      " [0.7 0.3]]\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo N = 3, D = 2\n",
    "Ex_1 = np.array([\n",
    "    [0.5, 0.3], \n",
    "    [0.2, 0.1], \n",
    "    [0.7, 0.3]\n",
    "])\n",
    "print(Ex_1)\n",
    "print(Ex_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrada en RNNs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secuencias de longitud fija\n",
    "\n",
    "NxTxD, donde T es la longitud de la secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5  0.3 ]\n",
      "  [0.2  0.1 ]\n",
      "  [0.7  0.3 ]]\n",
      "\n",
      " [[0.54 0.1 ]\n",
      "  [0.23 0.3 ]\n",
      "  [0.9  0.1 ]]\n",
      "\n",
      " [[0.5  0.3 ]\n",
      "  [0.2  0.1 ]\n",
      "  [0.7  0.3 ]]\n",
      "\n",
      " [[0.54 0.1 ]\n",
      "  [0.23 0.3 ]\n",
      "  [0.9  0.1 ]]]\n",
      "(4, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo N = 4, T = 3, D=2\n",
    "Ex_2 = np.array([\n",
    "    [\n",
    "        [0.5, 0.3], \n",
    "        [0.2, 0.1], \n",
    "        [0.7, 0.3]\n",
    "    ], \n",
    "    [\n",
    "        [0.54, 0.1], \n",
    "        [0.23, 0.3], \n",
    "        [0.9, 0.1]\n",
    "    ], \n",
    "    [\n",
    "        [0.5, 0.3], \n",
    "        [0.2, 0.1], \n",
    "        [0.7, 0.3]\n",
    "    ], \n",
    "    [\n",
    "        [0.54, 0.1], \n",
    "        [0.23, 0.3], \n",
    "        [0.9, 0.1]\n",
    "    ]\n",
    "])\n",
    "print(Ex_2)\n",
    "print(Ex_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secuencias de longitud variable (1 <= T <= 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([[0.5, 0.3], [0.7, 0.3]])\n",
      " list([[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]]) list([[0.7, 0.3]])\n",
      " list([[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]])]\n",
      "Samples: (4,)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "Ex_3 = np.array([\n",
    "    [\n",
    "        [0.5, 0.3], \n",
    "        [0.7, 0.3]\n",
    "    ], \n",
    "    [\n",
    "        [0.54, 0.1], \n",
    "        [0.23, 0.3], \n",
    "        [0.9, 0.1]\n",
    "    ], \n",
    "    [\n",
    "        [0.7, 0.3]\n",
    "    ], \n",
    "    [\n",
    "        [0.54, 0.1], \n",
    "        [0.23, 0.3], \n",
    "        [0.9, 0.1]\n",
    "    ]\n",
    "])\n",
    "print(Ex_3)\n",
    "print(f'Samples: {Ex_3.shape}')\n",
    "print(np.array(Ex_3[0]).shape)\n",
    "print(np.array(Ex_3[1]).shape)\n",
    "print(np.array(Ex_3[2]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tensorflow es posible, en keras se suele hacer padding\n",
    "\n",
    "¿Que pasa cuando tenemos longitudes distintas? Analizar el unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desventajas de padding\n",
    "- Podría haber una secuencia de longitud mayor en el test set. Que hacemos con eso?\n",
    "- Es probable que los casos de secuencia largas sean poco probables por lo que realizaremos multiplicaciones de matrices innecesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de preparación de datos para una RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción del valor de la acción de Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir el valor de las acciones de una compañia.\n",
    "- Se utilizarán las 5 observaciones anteriores \n",
    "- Tenemos los datos de 138 días\n",
    "- ¿Cuanto vale N, T, D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de samples: 138\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "apple_stock = np.loadtxt('apple/normalized_apple_prices.csv')\n",
    "plt.plot(apple_stock)\n",
    "plt.show()\n",
    "print(f'Cantidad de samples: {len(apple_stock)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X(0:5): [-0.70062339 -0.82088484 -0.93938305 -0.9471652  -0.68785527], y(5): -0.8432590195361995\n",
      "X(1:6): [-0.82088484 -0.93938305 -0.9471652  -0.68785527 -0.84325902], y(6): -0.8053201783108936\n",
      "X(2:7): [-0.93938305 -0.9471652  -0.68785527 -0.84325902 -0.80532018], y(7): -0.820580730773294\n",
      "X(3:8): [-0.9471652  -0.68785527 -0.84325902 -0.80532018 -0.82058073], y(8): -0.9202312393102279\n"
     ]
    }
   ],
   "source": [
    "def window_transform_series(series, window_size):\n",
    "    # containers for input/output pairs\n",
    "    X, y = [], []\n",
    "\n",
    "    # Lenght of series\n",
    "    N = series.shape[0]\n",
    "    \n",
    "    # Generate inputs and outputs\n",
    "    for i in range(N - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "        if i <=3:\n",
    "            print(f'X({i}:{i+window_size}): {series[i:i+window_size]}, y({i+window_size}): {series[i+window_size]}')\n",
    "        \n",
    "\n",
    "    # reshape each \n",
    "    X = np.asarray(X)\n",
    "    X.shape = (X.shape[0:2])\n",
    "    \n",
    "    y = np.asarray(y)\n",
    "    y.shape = (len(y),1)\n",
    "    return X,y\n",
    "\n",
    "X_, y = window_transform_series(apple_stock, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 5)\n",
      "[[-0.70062339 -0.82088484 -0.93938305 -0.9471652  -0.68785527]\n",
      " [-0.82088484 -0.93938305 -0.9471652  -0.68785527 -0.84325902]\n",
      " [-0.93938305 -0.9471652  -0.68785527 -0.84325902 -0.80532018]]\n",
      "(133, 1)\n",
      "[[-0.84325902]\n",
      " [-0.80532018]\n",
      " [-0.82058073]\n",
      " [-0.92023124]]\n"
     ]
    }
   ],
   "source": [
    "print(X_.shape)\n",
    "print(X_[0:3,:])\n",
    "print(y.shape)\n",
    "print(y[0:4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que no se toman lo 5 ultimos valores? Por que no hay un valor y correspondiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parece un detalle pero las capas recurrentes en Keras exigen el siguente formato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "===========>> (N, T, D): (133, 5, 1) <<===========\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_.reshape(X_.shape[0], X_.shape[1], 1)\n",
    "\n",
    "print(f'\\n\\n\\n===========>> (N, T, D): {X.shape} <<===========\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.70062339]\n",
      "  [-0.82088484]\n",
      "  [-0.93938305]\n",
      "  [-0.9471652 ]\n",
      "  [-0.68785527]]\n",
      "\n",
      " [[-0.82088484]\n",
      "  [-0.93938305]\n",
      "  [-0.9471652 ]\n",
      "  [-0.68785527]\n",
      "  [-0.84325902]]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(apple_stock[:30])\n",
    "i1 = 0\n",
    "plt.plot(range(i1,i1+5),X_[i1])\n",
    "plt.scatter(i1+5, y[i1], marker='x', color='k')\n",
    "i1 = 10\n",
    "plt.plot(range(i1,i1+5),X_[i1])\n",
    "plt.scatter(i1+5, y[i1], marker='x', color='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de lenguaje\n",
    "Predecir el siguiente caracter en función de los caracteres anteriores:\n",
    "- Utilizar one-hot encoding para los caracteres\n",
    "- Tamaño de ventana de 100\n",
    "- Cantidad total de caracteres de la obra: 67561\n",
    "- Cantidad de caracteres diferentes: 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Cantidad de caracteres: 67561\n",
      "Cantidad de caracteres unicos: 71\n",
      "['\\n', ' ', '!', '(', ')', ',', '.', '1', '2', '3', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '¿', 'É', 'Ñ', 'á', 'é', 'í', 'ñ', 'ó', 'ú']\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "BODAS DE SANGRE(1933)\n",
      "\n",
      "Poema trágico en tres actos y siete cuadros\n",
      "\n",
      "Personajes\n",
      " \n",
      "Madre\n",
      "Criada\n",
      "Leonardo\n",
      "Mozos\n",
      "Novia\n",
      "Vecina\n",
      "Novio\n",
      "Leñadores\n",
      "Suegra\n",
      "Muchachas\n",
      "Padre de la novia\n",
      "Mozos\n",
      "Mujer de Leonardo\n",
      "Luna\n",
      "Muerte (como mendiga)\n",
      "\n",
      "Acto primero\n",
      "\n",
      "CUADRO PRIMERO\n",
      "\n",
      "Habitación pintada de amarillo.\n",
      "\n",
      "NOVIO: (Entrando) Madre.\n",
      "\n",
      "MADRE: ¿Que?\n",
      "\n",
      "NOVIO:Me voy.\n",
      "\n",
      "MADRE: ¿Adónde?\n",
      "\n",
      "NOVIO:A la viña. (Va a salir)\n",
      "\n",
      "MADRE: Espera.\n",
      "\n",
      "NOVIO:¿Quieres algo?\n",
      "\n",
      "MADRE: Hijo, el almuerzo.\n",
      "\n",
      "NOVIO: Déjalo. Comeré uvas. Dame la navaja.\n",
      "\n",
      "MADRE: ¿Para qué?\n",
      "\n",
      "NOVIO: (Riendo) Para cortarlas.\n",
      "\n",
      "MADRE: (Entre dientes y buscándola) La navaja, la navaja... Malditas sean todas y el bribón que las inventó.\n",
      "\n",
      "NOVIO: Vamos a otro asunto.\n",
      "\n",
      "MADRE: Y las escopetas, y las pistolas, y el cuchillo más pequeño, y hasta las azadas y los bieldos de la era.\n",
      "\n",
      "NOVIO: Bueno.\n",
      "\n",
      "MADRE: Todo lo que puede cortar el cuerpo de un hombre. Un hombre hermoso, con su flor en la boca, que sale a las viñas o va a sus olivos propios, porque son de él, heredados...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open('federico-garcia-lorca/bodas_de_sangre.txt').read()\n",
    "number_of_chars = len(text)\n",
    "all_chars = sorted(set(text))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print('Cantidad de caracteres: ' + str(number_of_chars))\n",
    "print('Cantidad de caracteres unicos: ' + str(len(all_chars)))\n",
    "print(all_chars)\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print()\n",
    "print(text[:997])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_transform_text(text, window_size, step_size):\n",
    "    # Containers for input/output pairs\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    # This is the number of iterations taking \n",
    "    # into acount the step_size and the window_size\n",
    "    N = int((len(text) - window_size) / step_size)\n",
    "\n",
    "    # Get inputs and outputs\n",
    "    for i in range(0, N, step_size):\n",
    "        inputs.append(text[i:i+window_size])\n",
    "        outputs.append(text[i+window_size])\n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 1\n",
    "\n",
    "inputs, outputs = window_transform_text(text, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BODAS DE SANGRE(1933)\n",
      "\n",
      "Poema trágico en tres actos y siete cuadros\n",
      "\n",
      "Personajes\n",
      " \n",
      "Madre\n",
      "Criada\n",
      "Leonar\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Salida: d\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ODAS DE SANGRE(1933)\n",
      "\n",
      "Poema trágico en tres actos y siete cuadros\n",
      "\n",
      "Personajes\n",
      " \n",
      "Madre\n",
      "Criada\n",
      "Leonard\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Salida: o\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print()\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print('Salida:',outputs[0])\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print()\n",
    "print(inputs[1])\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print('Salida:',outputs[1])\n",
    "print('-----------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Como ingresamos a la red con caracteres?\n",
    "### Categorical Data (One-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_io_pairs(text,chars, window_size,step_size):\n",
    "    num_chars = len(chars)\n",
    "    chars_to_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char not in chars_to_indices:\n",
    "                char = ' '\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        out_char = outputs[i]\n",
    "        if out_char not in chars_to_indices:\n",
    "            out_char = ' '\n",
    "        y[i, chars_to_indices[out_char]] = 1\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = encode_io_pairs(text, all_chars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres codificado\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print('Caracteres codificado')\n",
    "print(X[0,0:5].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N,T,D):\n",
      "(67461, 100, 71)\n"
     ]
    }
   ],
   "source": [
    "print('(N,T,D):')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN en Keras\n",
    "Definamos una capa RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 71)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_neurons = 2\n",
    "time_steps = 1000# T\n",
    "n_features = 71 # D\n",
    "input_shape = (time_steps, n_features)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 2)                 148       \n",
      "=================================================================\n",
      "Total params: 148\n",
      "Trainable params: 148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons, input_shape = input_shape))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- Crece la cantidad de parametros con la cantidad de time_steps? \n",
    "Re: No.\n",
    "- Como puedo utilizar un MLP para que tenga en cuenta los time_steps? Que desventajas tengo? \n",
    "Re: Cada entrada es un timestep. Desventaja supongo que la memoria es elnumero de entradas y no se concerva estado entre ejecuciones.\n",
    "- rnn_neurons = 1, n_features = 1, por que es 3? Cuales son en el diagrama?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_number_of_parameters = lambda rnn_neurons, n_features: rnn_neurons * n_features + rnn_neurons**2 + rnn_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_parameters(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleRNN + Dense para predecir caracteres\n",
    "Armar modelo con los siguientes datos:\n",
    "N,T,D = (67461, 100, 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 71)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (67461, 100, 71)\n",
    "rnn_neurons = 200 # Hyperparametro para jugar\n",
    "time_steps = 100 # T\n",
    "n_features =  71 # D\n",
    "\n",
    "input_shape = (time_steps, n_features)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 100, 200)          54400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100, 71)           14271     \n",
      "=================================================================\n",
      "Total params: 68,671\n",
      "Trainable params: 68,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons, input_shape = input_shape, return_sequences=True))\n",
    "model.add(Dense(n_features, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- La cantidad de neuronas de la RNN queda para jugar (Overfitting, underfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleRNN + Dense para stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 40\n",
    "rnn_cells = 10\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(rnn_cells, input_shape = (window_size,1)))\n",
    "model_rnn.add(Dense(1))\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- Capa densa. Que función de activación estamos usando? Lineal f(x)= x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un error común"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_5 (SimpleRNN)     (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 521\n",
      "Trainable params: 521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn_error = Sequential()\n",
    "model_rnn_error.add(SimpleRNN(rnn_cells, input_shape = (1, window_size)))\n",
    "model_rnn_error.add(Dense(1))\n",
    "model_rnn_error.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas:\n",
    "- Que diferencia hay con la anterior? Solo hay un timestep.\n",
    "- Por que la diferencia en cantidad de parámetros?\n",
    "- Se puede pensar como un FNN (MLP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFN (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fnn = Sequential()\n",
    "model_fnn.add(Dense(rnn_cells, input_shape=(window_size,) ))\n",
    "model_fnn.add(Dense(1))\n",
    "model_fnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN\n",
      "(1, 10)\n",
      "(10, 10)\n",
      "(10,)\n",
      "\n",
      "RNN common error\n",
      "(40, 10)\n",
      "(10, 10)\n",
      "(10,)\n",
      "\n",
      "MLP\n",
      "(40, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print('RNN')\n",
    "print(model_rnn.layers[0].get_weights()[0].shape)\n",
    "print(model_rnn.layers[0].get_weights()[1].shape)\n",
    "print(model_rnn.layers[0].get_weights()[2].shape)\n",
    "print()\n",
    "print('RNN common error')\n",
    "print(model_rnn_error.layers[0].get_weights()[0].shape)\n",
    "print(model_rnn_error.layers[0].get_weights()[1].shape)\n",
    "print(model_rnn_error.layers[0].get_weights()[2].shape)\n",
    "print()\n",
    "print('MLP')\n",
    "print(model_fnn.layers[0].get_weights()[0].shape)\n",
    "print(model_fnn.layers[0].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como se podría entrener los ejemplos de STOCK Market y texto de manera mas eficiente con Many-to-Many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking RNNs\n",
    "### Podemos stackear varias capas?\n",
    "![stack%20units.png](stack units.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 71)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No funciona por que la salida no tiene la dimensión correcta\n",
    "# (67461, 100, 71)\n",
    "rnn_neurons = 100 # Hyperparametro para jugar\n",
    "time_steps = 100 # T\n",
    "n_features =  71# D\n",
    "\n",
    "input_shape = (time_steps, n_features)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer simple_rnn_9: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1703a18ee998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer simple_rnn_9: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons, input_shape = input_shape))\n",
    "model.add(SimpleRNN(rnn_neurons))\n",
    "model.add(Dense(n_features, input_shape = input_shape, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que falla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 71)\n"
     ]
    }
   ],
   "source": [
    "# (67461, 100, 71)\n",
    "rnn_neurons_1 = 200 # Hyperparametro para jugar\n",
    "rnn_neurons_2 = 150 # Hyperparametro para jugar\n",
    "time_steps = 100 # T\n",
    "n_features =  71# D\n",
    "input_shape = (time_steps, n_features)\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, 100, 200)          54400     \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 150)               52650     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 71)                10721     \n",
      "=================================================================\n",
      "Total params: 117,771\n",
      "Trainable params: 117,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons_1, input_shape = input_shape, return_sequences=True))\n",
    "model.add(SimpleRNN(rnn_neurons_2))\n",
    "model.add(Dense(n_features, input_shape = input_shape, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPTT (Back-Propagation Through Time)\n",
    "https://machinelearningmastery.com/truncated-backpropagation-through-time-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BPTT.png](BPTT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos calcular la \"cross-entropy\" y derivar respecto a $W_o$,$W_h$ y W_x para hallar el gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BPTT_graph.png](BPTT_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema: Vanishing/Exploding Gradient\n",
    "Soluciones:\n",
    "- Gradient Cliping\n",
    "- Truncated BPTT (Limitar la cantidad de unfoldings)\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumiendo:\n",
    "## RNN vs Vanilla Network\n",
    "- Menor cantidad de parametros para resolver lo mismo\n",
    "- En principio una FFN podria resolver con la misma precisión un problema resuelto por una RNN, pero es demasiado complejo encontrar la solución\n",
    "- La estructura de la RNN simplifica la tarea de encontrar una solución de manera eficiente\n",
    "- Ya sabemos que el problema tiene naturaleza recurrente (necesitamos memoria)\n",
    "- FNN tienen que tener tamaño fijo en contraste con las RNNs\n",
    "\n",
    "## Las RNN pueden resolver problemas muy diferentes desde el punto de vista del tipo de procesamiento sobre la secuencia\n",
    "- Secuencia temporal modelada con \"longitud infinita\": Valor de acciones - Modelos tipo AR(N)\n",
    "- Secuencias finitas \"independientes\" unas de otras: Sentiment analisys (Longitud variable), paridad (Longitud fija)\n",
    "- Modelos de lenguaje: Por caracter o por palabra\n",
    "- Seq2Seq: Traducción, chatbots, Image captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory) y GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que un modelo de lenguaje genere texto de este tipo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). **His** work is also known for its influence on the philosophy of science. **He** is best known by the general public for his mass–energy equivalence formula E = mc2 (which has been dubbed \"the world's most famous equation\"). **He** received the 1921 Nobel Prize in Physics \"for **his** services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the evolution of quantum theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos memoria a largo plazo, que \"recuerde\" que se esta hablando de una persona de genero masculino y respete la gramática a lo largo del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm.png](lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f -> forget Gate: \"Porcentaje\" que se queda de la LTM anterior\n",
    "- i -> Remeber Gate: \"Porcentaje\" que pasa de lo actual\n",
    "- o -> Learn Gate: \"Porcentaje\" a la salida o H (Recordar que h y la salida son lo mismo o STM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Cantidad de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "rnn_neurons = 1\n",
    "time_steps = 100 # T\n",
    "n_features = 1 # D\n",
    "input_shape = (time_steps, n_features)\n",
    "\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(rnn_neurons, input_shape = input_shape))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_number_of_LSTM_params = lambda rnn_neurons, n_features: (rnn_neurons*n_features + rnn_neurons**2 + rnn_neurons)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_LSTM_params(rnn_neurons, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En las GRU $i_t$ y $f_t$ son complementarias $i_t + f_t=1$ por lo tanto las GRUs poseen menos parametros. Ademas, no se hace diferencia entre $c_t$ y $h_t$\n",
    "\n",
    "### En las LSTM $c_t$ y $h_t$ son diferentes por lo que el estado de la celula es diferente a la salida. Esto es diferente tanto en la simpleRNN como en la GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo usando Model Api de Keras\n",
    "https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "Tensor(\"Encoder_LSTM_1/transpose_1:0\", shape=(?, ?, 256), dtype=float32)\n",
      "Tensor(\"Encoder_LSTM_1/while/Exit_2:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"Encoder_LSTM_1/while/Exit_3:0\", shape=(?, 256), dtype=float32)\n",
      "\n",
      "GRU\n",
      "Tensor(\"Encoder_GRU_3/transpose_1:0\", shape=(?, ?, 256), dtype=float32)\n",
      "Tensor(\"Encoder_GRU_3/while/Exit_2:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, TimeDistributed\n",
    "\n",
    "features = 100\n",
    "cells = 256\n",
    "return_sequences=True\n",
    "\n",
    "input_data = Input(shape=(None, features), name=\"inputs\")\n",
    "LSTM_cell = LSTM(cells, return_state=True, return_sequences=return_sequences, name=\"Encoder_LSTM\")\n",
    "LSTM_outputs, LSTM_state_h, LSTM_state_c = LSTM_cell(input_data)\n",
    "\n",
    "print('LSTM')\n",
    "print(LSTM_outputs) # LSTM_outputs y LSTM_state_h son diferentes solo si return_sequences=True\n",
    "print(LSTM_state_h)\n",
    "print(LSTM_state_c)\n",
    "print()\n",
    "\n",
    "GRU_cell = GRU(cells, return_state=True, return_sequences=return_sequences, name=\"Encoder_GRU\")\n",
    "GRU_outputs, GRU_state_h = GRU_cell(input_data)\n",
    "print('GRU')\n",
    "print(GRU_outputs)\n",
    "print(GRU_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Encoder_LSTM_1/transpose_1:0\", shape=(?, ?, 256), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer Encoder_GRU: expected shape=(None, None, 100), found shape=(None, None, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-641226e7536f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRU_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/toxic-comments/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    366\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                                     \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                                     str(x_shape))\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer Encoder_GRU: expected shape=(None, None, 100), found shape=(None, None, 256)"
     ]
    }
   ],
   "source": [
    "# Esto es solo un ejemplo de como definir el modelo Model Api en Keras\n",
    "# La cantidad de neuronas de la GRU tiene que ser igual a la cantidad de features \n",
    "# con lo que sale de la LSTM. Tambien return_sequences tiene que ser True\n",
    "print(LSTM_outputs)\n",
    "\n",
    "stacked_output, _ = GRU_cell(LSTM_outputs)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=stacked_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.wrappers.Bidirectional object at 0xb3c535a20>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lstm_5/transpose_1:0' shape=(?, ?, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_5/while/Exit_2:0' shape=(?, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_5/while/Exit_3:0' shape=(?, 256) dtype=float32>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Bidirectional\n",
    "features = 256\n",
    "cells = 256\n",
    "return_sequences=True\n",
    "\n",
    "input_data = Input(shape=(None, features))\n",
    "LSTM_cell = LSTM(cells, return_state=True, return_sequences=return_sequences)\n",
    "Bi_LSTM_cell = Bidirectional(LSTM_cell)\n",
    "print(Bi_LSTM_cell)\n",
    "LSTM_cell(input_data)\n",
    "#LSTM_outputs, LSTM_state_h2, LSTM_state_h1, LSTM_state_c1, LSTM_state_c2 = Bi_LSTM_cell(input_data)\n",
    "#print('LSTM')\n",
    "#print(LSTM_outputs) # LSTM_outputs y LSTM_state_h son diferentes solo si return_sequences=True\n",
    "#print(LSTM_state_h)\n",
    "#print(LSTM_state_c)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicaciones\n",
    "- Traducción\n",
    "- **No es buena** para predecir el futuro en secuencias temporales\n",
    "- Clasificación de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BiLSTM-Image-classif.png](biLSTM-image-class-complete.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](BiLSTM-Image-classif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
